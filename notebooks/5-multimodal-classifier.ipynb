{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# H. Multimodal Classifier for the LAV-DF Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_6_GWkhF0UR"
      },
      "source": [
        "Set Up Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "982owbO0t8rd",
        "outputId": "a1b141ee-ada5-46b0-d45f-fb98725d4abb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxi4fZWhtsVV",
        "outputId": "f7ede9bf-608e-456d-b96f-897de6c876bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded audio predictions: (3968, 9)\n",
            "Unique video_ids in audio: 3968\n",
            "Loaded ensemble predictions: (1909, 7)\n",
            "Merged dataset: (1909, 17)\n",
            "\n",
            "Saved merged dataset to:\n",
            " /content/drive/My Drive/Deep Fake Dataset/merged_audio_video_predictions.csv\n",
            "\n",
            "PREVIEW:\n",
            "   video_id    filename  true_label  prob_fake  pred_default  modify_audio  \\\n",
            "0     14471  014471.mp4           0   0.000066             0         False   \n",
            "1     13733  013733.mp4           0   0.000052             0         False   \n",
            "2     17940  017940.mp4           0   0.000002             0         False   \n",
            "3     25884  025884.mp4           0   0.000106             0         False   \n",
            "4     31736  031736.mp4           1   0.523087             1          True   \n",
            "\n",
            "   modify_video  duration  n_fakes  audio_score  audio_confidence  \\\n",
            "0         False     5.952        0     0.000066          0.999934   \n",
            "1         False     8.896        0     0.000052          0.999948   \n",
            "2         False     5.440        0     0.000002          0.999998   \n",
            "3         False     4.736        0     0.000106          0.999894   \n",
            "4          True     9.344        1     0.523087          0.523087   \n",
            "\n",
            "   ensemble_pred  svm  dt  knn  nb  \n",
            "0              0    0   0    0   0  \n",
            "1              0    0   0    0   0  \n",
            "2              0    0   0    0   0  \n",
            "3              0    0   0    0   0  \n",
            "4              1    1   1    1   1  \n"
          ]
        }
      ],
      "source": [
        "#LOAD OUTPUTS OF AUDIO AND VIDEO MODEL AND CONSTRUCT A MERGED DATASET\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# config\n",
        "DRIVE_FOLDER = \"/content/drive/My Drive/Deep Fake Dataset\"\n",
        "AUDIO_CSV = os.path.join(DRIVE_FOLDER, \"predictions_audio_FINAL2.csv\")\n",
        "ENSEMBLE_CSV = os.path.join(DRIVE_FOLDER, \"ensemble_predictions_lav.csv\")\n",
        "OUT_CSV = os.path.join(DRIVE_FOLDER, \"merged_audio_video_predictions.csv\")\n",
        "\n",
        "# function to extract the vid ID\n",
        "def extract_video_id_from_path(path):\n",
        "    \"\"\"\n",
        "    Extracts numeric digits from filename.\n",
        "    /path/to/train/034843.mp4 --> 34843\n",
        "    \"\"\"\n",
        "    if pd.isna(path):\n",
        "        return np.nan\n",
        "    base = os.path.basename(str(path))\n",
        "    m = re.search(r\"(\\d+)\", base)\n",
        "    if not m:\n",
        "        return np.nan\n",
        "    return int(m.group(1))\n",
        "\n",
        "# load audio predictions\n",
        "df_audio = pd.read_csv(AUDIO_CSV)\n",
        "print(\"Loaded audio predictions:\", df_audio.shape)\n",
        "df_audio[\"filename\"] = df_audio[\"file_rel\"].apply(os.path.basename)\n",
        "\n",
        "# Extract numeric video_id\n",
        "df_audio[\"video_id\"] = df_audio[\"filename\"].apply(extract_video_id_from_path)\n",
        "df_audio[\"video_id\"] = pd.to_numeric(df_audio[\"video_id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "print(\"Unique video_ids in audio:\", df_audio[\"video_id\"].nunique())\n",
        "\n",
        "# load video ensemble predictions\n",
        "df_ens = pd.read_csv(ENSEMBLE_CSV)\n",
        "print(\"Loaded ensemble predictions:\", df_ens.shape)\n",
        "\n",
        "df_ens[\"video_id\"] = pd.to_numeric(df_ens[\"video_id\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "# merge audio & video into one dataset\n",
        "merged = pd.merge(\n",
        "    df_audio,\n",
        "    df_ens,\n",
        "    on=\"video_id\",\n",
        "    how=\"inner\",\n",
        "    suffixes=(\"_audio\", \"_video\")\n",
        ")\n",
        "\n",
        "print(\"Merged dataset:\", merged.shape)\n",
        "\n",
        "# feature engineering\n",
        "# audio_score = prob_fake\n",
        "merged[\"audio_score\"] = pd.to_numeric(merged[\"prob_fake\"], errors=\"coerce\")\n",
        "\n",
        "# audio_confidence = max(p, 1-p)\n",
        "merged[\"audio_confidence\"] = merged[\"audio_score\"].apply(\n",
        "    lambda p: np.nan if pd.isna(p) else max(p, 1 - p)\n",
        ")\n",
        "\n",
        "# true_label from audio CSV ('real'/'fake')\n",
        "def map_label(x):\n",
        "    if isinstance(x, str):\n",
        "        x = x.strip().lower()\n",
        "        if x == \"real\": return 0\n",
        "        if x == \"fake\": return 1\n",
        "    try:\n",
        "        return int(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "merged[\"true_label\"] = merged[\"label\"].apply(map_label)\n",
        "\n",
        "# Drop rows missing label\n",
        "merged = merged[merged[\"true_label\"].notna()].copy()\n",
        "\n",
        "# select final columns\n",
        "keep_cols = [\n",
        "    \"video_id\",\n",
        "    \"filename\",\n",
        "    \"true_label\",\n",
        "\n",
        "    # AUDIO fields\n",
        "    \"prob_fake\",\n",
        "    \"pred_default\",\n",
        "    \"modify_audio\",\n",
        "    \"modify_video\",\n",
        "    \"duration\",\n",
        "    \"n_fakes\",\n",
        "    \"audio_score\",\n",
        "    \"audio_confidence\",\n",
        "\n",
        "    # VIDEO ENSEMBLE fields\n",
        "    \"ensemble_pred\",\n",
        "    \"svm\",\n",
        "    \"dt\",\n",
        "    \"knn\",\n",
        "    \"nb\",\n",
        "]\n",
        "\n",
        "final_df = merged[keep_cols]\n",
        "\n",
        "# SAVE\n",
        "final_df.to_csv(OUT_CSV, index=False)\n",
        "print(\"\\nSaved merged dataset to:\\n\", OUT_CSV)\n",
        "\n",
        "print(\"\\nPREVIEW:\")\n",
        "print(final_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULgeMUDxwF21",
        "outputId": "66d1bfbd-0fbd-4837-c8c5-d81c0f85a07c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded merged dataset: (1909, 16)\n",
            "Label distribution:\n",
            "true_label\n",
            "0    1057\n",
            "1     852\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- MODEL ACCURACY METRICS ---\n",
            "Video Ensemble Accuracy (ensemble_pred vs true_label): 96.33%\n",
            "Audio Model Accuracy (pred_default vs true_label):     98.06%\n"
          ]
        }
      ],
      "source": [
        "#Checking accuracies of independent classifiers on final filtered dataset\n",
        "\n",
        "MERGED_CSV = f\"{DRIVE_FOLDER}/merged_audio_video_predictions.csv\"\n",
        "\n",
        "# Load merged dataset\n",
        "df = pd.read_csv(MERGED_CSV)\n",
        "print(\"Loaded merged dataset:\", df.shape)\n",
        "\n",
        "# Ensure true_label numeric 0/1\n",
        "def map_label(x):\n",
        "    if isinstance(x, str):\n",
        "        x = x.lower().strip()\n",
        "        if x == \"real\": return 0\n",
        "        if x == \"fake\": return 1\n",
        "    try:\n",
        "        return int(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df[\"true_label\"] = df[\"true_label\"].apply(map_label)\n",
        "df = df[df[\"true_label\"].notna()].copy()\n",
        "df[\"true_label\"] = df[\"true_label\"].astype(int)\n",
        "\n",
        "print(\"Label distribution:\")\n",
        "print(df[\"true_label\"].value_counts())\n",
        "\n",
        "# Accuracy: ensemble_pred vs true_label (video model)\n",
        "df[\"ensemble_correct\"] = (df[\"ensemble_pred\"] == df[\"true_label\"])\n",
        "ensemble_acc = df[\"ensemble_correct\"].mean() * 100\n",
        "\n",
        "# Accuracy: pred_default vs true_label (audio model)\n",
        "df[\"audio_correct\"] = (df[\"pred_default\"] == df[\"true_label\"])\n",
        "audio_acc = df[\"audio_correct\"].mean() * 100\n",
        "\n",
        "# Print results\n",
        "print(\"\\n--- MODEL ACCURACY METRICS ---\")\n",
        "print(f\"Video Ensemble Accuracy (ensemble_pred vs true_label): {ensemble_acc:.2f}%\")\n",
        "print(f\"Audio Model Accuracy (pred_default vs true_label):     {audio_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTgPzgttvzNl",
        "outputId": "b239395e-f98c-41de-87ae-5ebc2a9f7dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded merged dataset: (1909, 16)\n",
            "Feature columns used: ['audio_score', 'audio_confidence', 'video_score', 'svm', 'dt', 'knn', 'nb']\n",
            "Using label column: true_label\n",
            "Label distribution:\n",
            "label_bin\n",
            "0    1057\n",
            "1     852\n",
            "Name: count, dtype: int64\n",
            "Saved imputer and scaler to Drive.\n",
            "Train size: 1527  Test size: 382\n",
            "Train distribution:\n",
            " label_bin\n",
            "0    0.553373\n",
            "1    0.446627\n",
            "Name: proportion, dtype: float64\n",
            "Test distribution:\n",
            " label_bin\n",
            "0    0.554974\n",
            "1    0.445026\n",
            "Name: proportion, dtype: float64\n",
            "Saved train/test CSVs to Drive.\n",
            "\n",
            "=== Logistic Regression Performance ===\n",
            "Accuracy: 0.9921465968586387\n",
            "AUC: 0.9995283018867924\n",
            "Precision: 1.0\n",
            "Recall: 0.9823529411764705\n",
            "Confusion matrix:\n",
            " [[212   0]\n",
            " [  3 167]]\n",
            "Saved logistic regression model: /content/drive/My Drive/Deep Fake Dataset/val_logreg.joblib\n",
            "\n",
            "=== MLP (1-layer) Performance ===\n",
            "Accuracy: 0.9921465968586387\n",
            "AUC: 0.9995837957824639\n",
            "Precision: 1.0\n",
            "Recall: 0.9823529411764705\n",
            "Confusion matrix:\n",
            " [[212   0]\n",
            " [  3 167]]\n",
            "Saved 1-layer MLP model: /content/drive/My Drive/Deep Fake Dataset/val_mlp.joblib\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score,\n",
        "    recall_score, confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Config\n",
        "DRIVE_FOLDER = \"/content/drive/My Drive/Deep Fake Dataset\"\n",
        "MERGED_CSV = os.path.join(DRIVE_FOLDER, \"merged_audio_video_predictions.csv\")  # merged audio + ensemble\n",
        "OUT_TRAIN = os.path.join(DRIVE_FOLDER, \"val_train_split.csv\")\n",
        "OUT_TEST = os.path.join(DRIVE_FOLDER, \"val_test_split.csv\")\n",
        "MODEL_LR = os.path.join(DRIVE_FOLDER, \"val_logreg.joblib\")\n",
        "MODEL_MLP = os.path.join(DRIVE_FOLDER, \"val_mlp.joblib\")\n",
        "IMPUTER_PATH = os.path.join(DRIVE_FOLDER, \"val_imputer.joblib\")\n",
        "SCALER_PATH = os.path.join(DRIVE_FOLDER, \"val_scaler.joblib\")\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Load merged dataset (audio + ensemble)\n",
        "if not os.path.exists(MERGED_CSV):\n",
        "    raise FileNotFoundError(f\"Could not find merged CSV at: {MERGED_CSV}\")\n",
        "\n",
        "df = pd.read_csv(MERGED_CSV)\n",
        "print(\"Loaded merged dataset:\", df.shape)\n",
        "\n",
        "# feature construction\n",
        "# audio_score = prob_fake (from audio CSV)\n",
        "df[\"audio_score\"] = pd.to_numeric(df[\"prob_fake\"], errors=\"coerce\")\n",
        "\n",
        "# audio_confidence = max(p, 1-p)\n",
        "df[\"audio_confidence\"] = df[\"audio_score\"].apply(lambda p: np.nan if pd.isna(p) else max(p, 1.0 - p))\n",
        "\n",
        "# video_score = ensemble_pred\n",
        "df[\"video_score\"] = pd.to_numeric(df[\"ensemble_pred\"], errors=\"coerce\")\n",
        "\n",
        "# Ensemble model outputs to include if present (svm, dt, knn, nb, etc.)\n",
        "ensemble_cols_candidates = [\"ensemble_pred\", \"svm\", \"dt\", \"knn\", \"nb\"]\n",
        "ensemble_cols_present = [c for c in ensemble_cols_candidates if c in df.columns]\n",
        "\n",
        "# Convert ensemble outputs to numeric\n",
        "for c in ensemble_cols_present:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# Build feature list: core audio/video features + any present ensemble outputs (excluding duplicates)\n",
        "feature_cols = [\"audio_score\", \"audio_confidence\", \"video_score\"]\n",
        "# Add ensemble outputs but avoid adding 'ensemble_pred' twice if video_score already maps to it\n",
        "for c in ensemble_cols_present:\n",
        "    if c == \"ensemble_pred\" and \"video_score\" in feature_cols:\n",
        "        continue\n",
        "    if c not in feature_cols:\n",
        "        feature_cols.append(c)\n",
        "\n",
        "print(\"Feature columns used:\", feature_cols)\n",
        "\n",
        "# label prep\n",
        "# use true_label column from merged CSV (should be 0/1)\n",
        "label_col = \"true_label\"\n",
        "\n",
        "def map_label_val(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    if isinstance(x, str):\n",
        "        s = x.strip().lower()\n",
        "        if s == \"real\": return 0\n",
        "        if s == \"fake\": return 1\n",
        "    try:\n",
        "        return int(float(x))\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df[\"label_bin\"] = df[label_col].apply(map_label_val)\n",
        "df = df[df[\"label_bin\"].notna()].copy()\n",
        "df[\"label_bin\"] = df[\"label_bin\"].astype(int)\n",
        "\n",
        "print(\"Label distribution:\")\n",
        "print(df[\"label_bin\"].value_counts())\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[\"label_bin\"]\n",
        "\n",
        "# impute + scale\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_imp = imputer.fit_transform(X)\n",
        "X_scaled = scaler.fit_transform(X_imp)\n",
        "\n",
        "joblib.dump(imputer, IMPUTER_PATH)\n",
        "joblib.dump(scaler, SCALER_PATH)\n",
        "print(\"Saved imputer and scaler to Drive.\")\n",
        "\n",
        "# STRATIFIED TRAIN/TEST SPLIT\n",
        "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
        "    X_scaled, y, df.index,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_train.shape[0], \" Test size:\", X_test.shape[0])\n",
        "print(\"Train distribution:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"Test distribution:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "# Save splits with original metadata\n",
        "df.loc[idx_train].to_csv(OUT_TRAIN, index=False)\n",
        "df.loc[idx_test].to_csv(OUT_TEST, index=False)\n",
        "print(\"Saved train/test CSVs to Drive.\")\n",
        "\n",
        "# LOGISTIC REGRESSION\n",
        "lr = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "y_proba_lr = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n=== Logistic Regression Performance ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "try:\n",
        "    print(\"AUC:\", roc_auc_score(y_test, y_proba_lr))\n",
        "except Exception as e:\n",
        "    print(\"AUC: could not compute:\", e)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_lr, zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_lr, zero_division=0))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
        "\n",
        "joblib.dump(lr, MODEL_LR)\n",
        "print(\"Saved logistic regression model:\", MODEL_LR)\n",
        "\n",
        "# MLP\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(16,),\n",
        "    activation=\"relu\",\n",
        "    solver=\"adam\",\n",
        "    max_iter=1000,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "# predict_proba may be available\n",
        "try:\n",
        "    y_proba_mlp = mlp.predict_proba(X_test)[:, 1]\n",
        "except:\n",
        "    y_proba_mlp = None\n",
        "\n",
        "print(\"\\n=== MLP (1-layer) Performance ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
        "if y_proba_mlp is not None:\n",
        "    try:\n",
        "        print(\"AUC:\", roc_auc_score(y_test, y_proba_mlp))\n",
        "    except Exception as e:\n",
        "        print(\"AUC: could not compute:\", e)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_mlp, zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_mlp, zero_division=0))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_mlp))\n",
        "\n",
        "joblib.dump(mlp, MODEL_MLP)\n",
        "print(\"Saved 1-layer MLP model:\", MODEL_MLP)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
