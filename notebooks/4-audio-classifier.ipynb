{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# G. Audio Classifier for the LAV-DF Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u18aXqo-Qop"
      },
      "source": [
        "Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKkMWZpz6mHI",
        "outputId": "58ad574d-82f7-4f10-8e83-cae355352dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Working Directory: /content/drive/.shortcut-targets-by-id/122_EfIpP6SceFMPeBakKwIQV2RWQRRjW/Deep Fake Dataset\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "\n",
        "try:\n",
        "    os.chdir(DATA_ROOT)\n",
        "    print(f\"Working Directory: {os.getcwd()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDp3_IjC8UyF"
      },
      "outputs": [],
      "source": [
        "!pip install -q librosa soundfile pydub tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHo_Aa2w8isN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "from pydub import AudioSegment\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAu3HjBO8mra"
      },
      "outputs": [],
      "source": [
        "# Path to MP4 files\n",
        "TRAIN_DIR = os.path.join(DATA_ROOT, 'LAV-DF', 'train')\n",
        "\n",
        "# Where to save WAVs\n",
        "WAV_CONVERT_DIR = os.path.join(DATA_ROOT, 'wav_converted')\n",
        "os.makedirs(WAV_CONVERT_DIR, exist_ok=True)\n",
        "\n",
        "# Where to save features\n",
        "FEATURE_DIR = os.path.join(DATA_ROOT, 'features')\n",
        "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
        "\n",
        "TARGET_SR = 16000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crh5f-Lv-LyO"
      },
      "source": [
        "Feature Extraction: Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ioSgPH49_hU"
      },
      "outputs": [],
      "source": [
        "#convert audio to WAV form\n",
        "def ensure_wav(input_path_to_read_audio, original_file_rel, out_dir, target_sr=TARGET_SR):\n",
        "    \"\"\"\n",
        "    Ensure audio is WAV (PCM 16-bit) with sample rate target_sr.\n",
        "    - input_path_to_read_audio: The actual path to the audio file (could be local temp or Drive path).\n",
        "    - original_file_rel: The relative path of the file *within the original dataset structure*\n",
        "                         (e.g., 'train/000001.mp4'). This is used to reconstruct output paths.\n",
        "    - Otherwise converts using pydub or ffmpeg to out_dir and returns converted path.\n",
        "    - Converted files keep relative structure to avoid collisions.\n",
        "    \"\"\"\n",
        "    input_path_to_read_audio = str(input_path_to_read_audio)\n",
        "\n",
        "    # Use original_file_rel to determine the output subdirectory structure\n",
        "    rel_dir_part = os.path.dirname(original_file_rel)\n",
        "    out_subdir = os.path.join(out_dir, rel_dir_part)\n",
        "    os.makedirs(out_subdir, exist_ok=True)\n",
        "\n",
        "    out_name = Path(original_file_rel).stem + '.wav'\n",
        "    out_path = os.path.join(out_subdir, out_name)\n",
        "\n",
        "    # If already converted and exists, return it\n",
        "    if os.path.exists(out_path):\n",
        "        return out_path\n",
        "\n",
        "    # Convert using pydub\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(input_path_to_read_audio) # autodetect format\n",
        "        # set frame rate / sample width (16-bit)\n",
        "        audio = audio.set_frame_rate(int(target_sr)).set_sample_width(2).set_channels(1)\n",
        "        audio.export(out_path, format='wav')\n",
        "    except Exception:\n",
        "        cmd = [\n",
        "            'ffmpeg', '-y', '-i', input_path_to_read_audio,\n",
        "            '-ar', str(target_sr), '-ac', '1', '-sample_fmt', 's16', out_path\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "    return out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsu_OA4EyKq-"
      },
      "outputs": [],
      "source": [
        "#to convert to numpy array\n",
        "def load_audio_mono(path, sr):\n",
        "    \"\"\"\n",
        "    Loads audio as mono float32 array using librosa.\n",
        "    - sr: target sample rate (resampling will occur if needed)\n",
        "    - duration: if provided (seconds), loads that much from start\n",
        "    Returns: y (np.float32), sr (int)\n",
        "    \"\"\"\n",
        "    y, sr = librosa.load(path, sr=sr, mono=True)\n",
        "    return y, sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGkbe4royupV"
      },
      "outputs": [],
      "source": [
        "def extract_basic_features(y, sr):\n",
        "    \"\"\"\n",
        "    Extracts a wide set of audio features useful for deepfake detection.\n",
        "    Each feature includes explanatory comments for clarity.\n",
        "    Returns a dictionary mapping: feature_name -> numpy array or scalar.\n",
        "    \"\"\"\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # 1. MFCCs (Mel-frequency cepstral coefficients)\n",
        "    # (describe the timbre/character of the voice)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    features['mfcc_mean'] = np.mean(mfcc, axis=1)  # average value per coefficient\n",
        "    features['mfcc_std']  = np.std(mfcc, axis=1)   # variation of each coefficient\n",
        "\n",
        "\n",
        "    # 2. Delta MFCCs (First derivative / velocity)\n",
        "    # (how MFCCs change over time)\n",
        "    delta_mfcc = librosa.feature.delta(mfcc, order=1)\n",
        "    features['mfcc_delta_mean'] = np.mean(delta_mfcc, axis=1)\n",
        "    features['mfcc_delta_std']  = np.std(delta_mfcc, axis=1)\n",
        "\n",
        "    # 3. Mel-spectrogram (mean across time)\n",
        "    # (how energy is distributed across mel frequency bands)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024,\n",
        "                                         hop_length=512, n_mels=40)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    features['mel_mean'] = np.mean(log_mel, axis=1)  # avg energy in each mel band\n",
        "\n",
        "    # 4. Spectral Contrast\n",
        "    # (contrast between peaks and valleys in frequency)\n",
        "    spec_con = librosa.feature.spectral_contrast(y=y, sr=sr,\n",
        "                                                 n_fft=1024, hop_length=512)\n",
        "    features['spec_con_mean'] = np.mean(spec_con, axis=1)\n",
        "\n",
        "    # 5. Chroma Features\n",
        "    # (related to pitch class (12 chroma bins))\n",
        "    chroma = librosa.feature.chroma_stft(y=y, sr=sr,\n",
        "                                         n_fft=1024, hop_length=512)\n",
        "    features['chroma_mean'] = np.mean(chroma, axis=1)\n",
        "\n",
        "\n",
        "    # 6. Zero-Crossing Rate (ZCR)\n",
        "    # (indicator of noisiness / fricatives)\n",
        "    zcr = librosa.feature.zero_crossing_rate(y, frame_length=1024,\n",
        "                                             hop_length=512)\n",
        "    features['zcr_mean'] = float(np.mean(zcr))\n",
        "    features['zcr_std']  = float(np.std(zcr))\n",
        "\n",
        "    # 7. Spectral Rolloff\n",
        "    # (frequency below which 85% of energy is contained)\n",
        "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85,\n",
        "                                               n_fft=1024, hop_length=512)\n",
        "    features['rolloff_mean'] = float(np.mean(rolloff))\n",
        "    features['rolloff_std']  = float(np.std(rolloff))\n",
        "\n",
        "\n",
        "    # 8. Spectral Flatness\n",
        "    # (measures tone-like vs noise-like quality)\n",
        "    flatness = librosa.feature.spectral_flatness(y=y,\n",
        "                                                 n_fft=1024, hop_length=512)\n",
        "    features['flatness_mean'] = float(np.mean(flatness))\n",
        "    features['flatness_std']  = float(np.std(flatness))\n",
        "\n",
        "\n",
        "    # 9. RMS Energy\n",
        "    # (overall loudness over time)\n",
        "    rms = librosa.feature.rms(y=y, frame_length=1024,\n",
        "                              hop_length=512)[0]\n",
        "    features['rms_mean'] = float(np.mean(rms))\n",
        "    features['rms_std']  = float(np.std(rms))\n",
        "\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgDOJYeEzifm"
      },
      "outputs": [],
      "source": [
        "def save_features(features_dict, src_audio_path, feature_dir=FEATURE_DIR):\n",
        "    \"\"\"\n",
        "    Saves all extracted features for one audio file into a compressed .npz file.\n",
        "\n",
        "    - Each feature becomes an array inside the .npz\n",
        "    - File is named after the audio file (e.g., \"example.wav\" -> \"example.npz\")\n",
        "    \"\"\"\n",
        "\n",
        "    # Turn the audio filepath into a safe filename\n",
        "    stem = Path(src_audio_path).stem\n",
        "    out_file = os.path.join(feature_dir, stem + '.npz')\n",
        "\n",
        "    # Convert feature dictionary values to NumPy arrays before saving\n",
        "    np_save_dict = {k: np.asarray(v) for k, v in features_dict.items()}\n",
        "\n",
        "    # Save compressed file with all features inside\n",
        "    np.savez_compressed(out_file, **np_save_dict)\n",
        "\n",
        "    return out_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwJnT_83PUGL"
      },
      "source": [
        "Loading Metadata & Creating Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "7y5Fx01nPTiB",
        "outputId": "488148d6-47bb-43c0-d839-8a8204ff9051"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Deep Fake Dataset/LAV-DF/metadata.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1720315525.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load and extract entries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mMETA_PATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Deep Fake Dataset/LAV-DF/metadata.json'"
          ]
        }
      ],
      "source": [
        "# Step 1: load metadata.json and build a dataset table\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Path to metadata file\n",
        "DATA_ROOT = Path('/content/drive/My Drive/Deep Fake Dataset')\n",
        "META_PATH = DATA_ROOT / 'LAV-DF' / 'metadata.json'\n",
        "\n",
        "# Load and extract entries\n",
        "with META_PATH.open('r', encoding='utf-8') as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "entries = (meta if isinstance(meta, list) else\n",
        "           meta.get('root') or meta.get('items') or\n",
        "           next((v for v in meta.values() if isinstance(v, list)), []))\n",
        "\n",
        "# Build rows\n",
        "rows = []\n",
        "for e in entries:\n",
        "    if not isinstance(e, dict):\n",
        "        continue\n",
        "\n",
        "    file_rel = e.get('file')\n",
        "    rows.append({\n",
        "        'file_rel': file_rel,\n",
        "        'filepath': str(DATA_ROOT / 'LAV-DF' / file_rel) if file_rel else None,\n",
        "        'split': e.get('split', 'unknown'),\n",
        "        'duration': e.get('duration'),\n",
        "        'transcript': e.get('transcript'),\n",
        "        'n_fakes': int(e.get('n_fakes') or 0),\n",
        "        'modify_audio': bool(e.get('modify_audio')),\n",
        "        'modify_video': bool(e.get('modify_video')),\n",
        "        'audio_channels': int(e.get('audio_channels') or 1),\n",
        "        'audio_frames': int(e.get('audio_frames') or 0),\n",
        "        'label': 'fake' if e.get('modify_audio') else 'real'\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df['exists_on_disk'] = df['filepath'].apply(lambda p: os.path.exists(p) if p else False)\n",
        "\n",
        "print(f\"Total metadata entries: {len(df)}\")\n",
        "print(df['split'].value_counts(dropna=False))\n",
        "print(df['label'].value_counts())\n",
        "print(f\"Files that exist on disk: {df['exists_on_disk'].sum()} / {len(df)}\")\n",
        "df.head(8)\n",
        "\n",
        "# Filter to existing files, inspect counts, and save per-split CSVs\n",
        "\n",
        "print(f\"Prior total metadata rows: {len(df)}\")\n",
        "\n",
        "df_ok = df[df['exists_on_disk']].copy()\n",
        "print(f\"Usable files (exists_on_disk=True): {len(df_ok)}\")\n",
        "print(\"\\nLabel distribution:\")\n",
        "print(df_ok['label'].value_counts())\n",
        "print(\"\\nSplit distribution:\")\n",
        "print(df_ok['split'].value_counts())\n",
        "print(\"\\nSample rows:\")\n",
        "display(df_ok[['file_rel','filepath','split','label','duration']].head(6))\n",
        "\n",
        "# Save per-split CSVs\n",
        "OUT_DIR = DATA_ROOT / 'metadata_splits'\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "cols = ['filepath','file_rel','label','duration','transcript','n_fakes','modify_audio','modify_video']\n",
        "for split_name, df_split in df_ok.groupby('split'):\n",
        "    out_path = OUT_DIR / f\"{split_name}.csv\"\n",
        "    df_split[cols].to_csv(out_path, index=False)\n",
        "    print(f\"Saved {len(df_split)} rows -> {out_path}\")\n",
        "\n",
        "print(f\"\\nDone. Find CSVs in: {OUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z24HKul0WBIC",
        "outputId": "702c9132-a901-4da1-c78c-6fb5a2c335de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total examples in input CSV: 25641\n",
            "\n",
            "Saved splits to: /content/drive/My Drive/Deep Fake Dataset/metadata_splits\n",
            "Train: 17948 examples -> /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_train.csv\n",
            "Val:   3846 examples -> /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_val.csv\n",
            "Test:  3847 examples -> /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_test.csv\n",
            "\n",
            "Label distribution (train / val / test):\n",
            "train:\n",
            " label\n",
            "real    9254\n",
            "fake    8694\n",
            "Name: count, dtype: int64\n",
            "val:\n",
            " label\n",
            "real    1983\n",
            "fake    1863\n",
            "Name: count, dtype: int64\n",
            "test:\n",
            " label\n",
            "real    1983\n",
            "fake    1864\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Stratified train/val/test split (70 / 15 / 15)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "IN_CSV = os.path.join(DATA_ROOT, 'metadata_splits', 'train.csv')\n",
        "OUT_DIR = os.path.join(DATA_ROOT, 'metadata_splits')\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "RANDOM_SEED = 42\n",
        "TRAIN_FRAC = 0.70\n",
        "VAL_FRAC = 0.15\n",
        "TEST_FRAC = 0.15\n",
        "\n",
        "# 1) Load the CSV with usable files\n",
        "df_all = pd.read_csv(IN_CSV)\n",
        "print(\"Total examples in input CSV:\", len(df_all))\n",
        "\n",
        "# 2) First split: train vs temp (temp will become val+test)\n",
        "train_df, temp_df = train_test_split(\n",
        "    df_all,\n",
        "    train_size=TRAIN_FRAC,\n",
        "    stratify=df_all['label'],\n",
        "    random_state=RANDOM_SEED,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 3) Second split: split temp into val and test equally so each is 15% of total\n",
        "val_rel_frac = VAL_FRAC / (1.0 - TRAIN_FRAC)\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    train_size=val_rel_frac,\n",
        "    stratify=temp_df['label'],\n",
        "    random_state=RANDOM_SEED,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 4) Save CSVs\n",
        "train_out = os.path.join(OUT_DIR, 'split_train.csv')\n",
        "val_out   = os.path.join(OUT_DIR, 'split_val.csv')\n",
        "test_out  = os.path.join(OUT_DIR, 'split_test.csv')\n",
        "\n",
        "train_df.to_csv(train_out, index=False)\n",
        "val_df.to_csv(val_out, index=False)\n",
        "test_df.to_csv(test_out, index=False)\n",
        "\n",
        "# Print summaries to confirm\n",
        "print(\"\\nSaved splits to:\", OUT_DIR)\n",
        "print(f\"Train: {len(train_df)} examples -> {train_out}\")\n",
        "print(f\"Val:   {len(val_df)} examples -> {val_out}\")\n",
        "print(f\"Test:  {len(test_df)} examples -> {test_out}\")\n",
        "\n",
        "print(\"\\nLabel distribution (train / val / test):\")\n",
        "print(\"train:\\n\", train_df['label'].value_counts())\n",
        "print(\"val:\\n\", val_df['label'].value_counts())\n",
        "print(\"test:\\n\", test_df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixA4ttYwXh4b"
      },
      "source": [
        "Extracting Traditional Acoustic Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUK3u358XBp-",
        "outputId": "77d6a371-631a-4615-851c-51ab551ecbf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed (from log): 3847\n",
            "Rows to process: 3847\n",
            "\n",
            "=== Processing batch 1-50 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 89278.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 51-100 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 142276.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 101-150 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 120387.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 151-200 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 91339.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 201-250 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 114723.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 251-300 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 37841.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 301-350 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 88115.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 351-400 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 84054.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 401-450 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 85563.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 451-500 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 96155.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 501-550 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 90668.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 551-600 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 95152.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 601-650 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 129373.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 651-700 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 141987.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 701-750 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 53308.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 751-800 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 58189.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 801-850 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 96287.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 851-900 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 90394.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 901-950 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 126869.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 951-1000 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 99911.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1001-1050 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 125427.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1051-1100 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 104700.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1101-1150 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 99816.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1151-1200 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 98875.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1201-1250 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 88189.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1251-1300 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 112993.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1301-1350 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 134432.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1351-1400 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 91419.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1401-1450 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 89775.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1451-1500 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 85354.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1501-1550 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 112629.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1551-1600 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 50207.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1601-1650 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 96376.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1651-1700 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 95108.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1701-1750 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 94254.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1751-1800 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 91538.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1801-1850 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 91658.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1851-1900 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 93206.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1901-1950 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 91538.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 1951-2000 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 32615.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2001-2050 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 89890.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2051-2100 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 36830.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2101-2150 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 124165.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2151-2200 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 94893.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2201-2250 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 89316.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2251-2300 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 97045.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2301-2350 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 68067.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2351-2400 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 121785.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2401-2450 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 83319.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2451-2500 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 47265.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2501-2550 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 139623.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2551-2600 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 92304.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2601-2650 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 94423.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2651-2700 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 72390.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2701-2750 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 89278.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2751-2800 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 93664.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2801-2850 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 90355.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2851-2900 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 133321.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2901-2950 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 98643.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 2951-3000 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 90825.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3001-3050 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 95238.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3051-3100 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 107271.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3101-3150 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 79739.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3151-3200 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 85111.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3201-3250 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 83585.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3251-3300 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 85843.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3301-3350 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 85111.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3351-3400 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 25609.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3401-3450 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 94000.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3451-3500 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 96509.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3501-3550 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 95455.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3551-3600 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 100438.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3601-3650 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 89813.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3651-3700 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 79018.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3701-3750 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 95411.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3751-3800 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 50/50 [00:00<00:00, 92794.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Processing batch 3801-3847 / 3847 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "batch files: 100%|██████████| 47/47 [00:00<00:00, 93516.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ALL BATCHES COMPLETE ===\n",
            "Features saved to: /content/drive/My Drive/Deep Fake Dataset/features/test\n",
            "Processed count: 3847\n"
          ]
        }
      ],
      "source": [
        "# feature extraction: copy to local tmp, convert locally, extract features, push small .npz to Drive\n",
        "import os, time, csv, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# user config\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "SPLIT_CSV = os.path.join(DATA_ROOT, 'metadata_splits', 'split_test.csv')\n",
        "OUT_FEATURE_DIR = os.path.join(DATA_ROOT, 'features', 'test')\n",
        "LOCAL_TMP = '/content/tmp_batch'\n",
        "BATCH_SIZE = 50\n",
        "MAX_RETRIES = 3\n",
        "RETRY_SLEEP = 8\n",
        "TARGET_SR = globals().get('TARGET_SR', 16000)\n",
        "USE_LOCAL_BATCH = True\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Make directories\n",
        "os.makedirs(OUT_FEATURE_DIR, exist_ok=True)\n",
        "os.makedirs(LOCAL_TMP, exist_ok=True)\n",
        "\n",
        "# processed-log so we can resume (store the names of the files)\n",
        "processed_log = os.path.join(DATA_ROOT, 'features', f'processed_log_{Path(SPLIT_CSV).stem}.csv')\n",
        "processed_set = set()\n",
        "if os.path.exists(processed_log):\n",
        "    with open(processed_log, 'r') as f:\n",
        "        for r in f:\n",
        "            r = r.strip()\n",
        "            if r:\n",
        "                processed_set.add(r)\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(SPLIT_CSV)\n",
        "n_total = len(df)\n",
        "print(f\"Rows to process: {n_total}\")\n",
        "\n",
        "# helper: retry wrapper\n",
        "def with_retries(fn, max_retries=MAX_RETRIES, sleep=RETRY_SLEEP, *args, **kwargs):\n",
        "    last_exc = None\n",
        "    for attempt in range(1, max_retries+1):\n",
        "        try:\n",
        "            return fn(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            print(f\"Attempt {attempt}/{max_retries} failed: {e}\")\n",
        "            time.sleep(sleep)\n",
        "    raise last_exc\n",
        "\n",
        "# safe chunked copy from Drive -> local\n",
        "def copy_bytes(src, dest, chunk_size=1024*1024):\n",
        "    os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
        "    with open(src, 'rb') as fr, open(dest, 'wb') as fw:\n",
        "        while True:\n",
        "            chunk = fr.read(chunk_size)\n",
        "            if not chunk:\n",
        "                break\n",
        "            fw.write(chunk)\n",
        "\n",
        "# save feature .npz on Drive\n",
        "def save_features_for_row(features_dict, file_rel, out_dir=OUT_FEATURE_DIR):\n",
        "    stem = Path(file_rel).stem\n",
        "    out_file = os.path.join(out_dir, stem + '.npz')\n",
        "    np_save = {k: np.asarray(v) for k, v in features_dict.items()}\n",
        "    np.savez_compressed(out_file, **np_save)\n",
        "    return out_file\n",
        "\n",
        "# append to processed log\n",
        "def log_processed(stem):\n",
        "    with open(processed_log, 'a') as f:\n",
        "        f.write(stem + \"\\n\")\n",
        "    processed_set.add(stem)\n",
        "\n",
        "# Main loop: batches\n",
        "rows = list(df.itertuples(index=False))\n",
        "i = 0\n",
        "while i < n_total:\n",
        "    batch_rows = rows[i:i+BATCH_SIZE]\n",
        "    i_end = i + len(batch_rows)\n",
        "    print(f\"\\n=== Processing batch {i+1}-{i_end} / {n_total} ===\")\n",
        "\n",
        "    # prepare local copies for the batch\n",
        "    if USE_LOCAL_BATCH:\n",
        "        # clean local tmp (only files from previous batch to avoid stale leftovers)\n",
        "        for fname in os.listdir(LOCAL_TMP):\n",
        "            try:\n",
        "                os.remove(os.path.join(LOCAL_TMP, fname))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # copy files to local tmp with retries\n",
        "        for r in batch_rows:\n",
        "            src_drive = getattr(r, 'filepath') if 'filepath' in df.columns else None\n",
        "            file_rel = getattr(r, 'file_rel')\n",
        "            local_name = Path(file_rel).name\n",
        "            dest_local = os.path.join(LOCAL_TMP, local_name)\n",
        "            if not src_drive:\n",
        "                continue\n",
        "            # do not copy if already exists locally\n",
        "            if os.path.exists(dest_local):\n",
        "                continue\n",
        "            try:\n",
        "                with_retries(lambda s=src_drive, d=dest_local: copy_bytes(s, d))\n",
        "            except Exception as e:\n",
        "                print(f\"[COPY FAILED] {src_drive} -> {dest_local}: {e}\")\n",
        "\n",
        "    # process files in this batch\n",
        "    for r in tqdm(batch_rows, desc=\"batch files\"):\n",
        "        file_rel = getattr(r, 'file_rel')\n",
        "        stem = Path(file_rel).stem\n",
        "        out_feature_path = os.path.join(OUT_FEATURE_DIR, stem + '.npz')\n",
        "\n",
        "        # skip if processed or output exists\n",
        "        if stem in processed_set or os.path.exists(out_feature_path):\n",
        "            continue\n",
        "\n",
        "        # determine source: local copy if present, else Drive path\n",
        "        local_src = os.path.join(LOCAL_TMP, Path(file_rel).name)\n",
        "        if os.path.exists(local_src):\n",
        "            src_path = local_src\n",
        "        else:\n",
        "            src_path = getattr(r, 'filepath')\n",
        "\n",
        "        try:\n",
        "            # convert MP4 -> WAV locally into LOCAL_TMP (so ensure_wav should write there)\n",
        "            wav_dir_local = LOCAL_TMP\n",
        "            wav_path = with_retries(lambda p=src_path: ensure_wav(p, file_rel, out_dir=wav_dir_local, target_sr=TARGET_SR))\n",
        "\n",
        "            # load audio (mono float32)\n",
        "            y, sr = load_audio_mono(wav_path, sr=TARGET_SR)\n",
        "\n",
        "            # extract features with function\n",
        "            feats = extract_basic_features(y, sr)\n",
        "\n",
        "            # save features to Drive\n",
        "            saved = save_features_for_row(feats, file_rel, OUT_FEATURE_DIR)\n",
        "            log_processed(stem)\n",
        "\n",
        "            # cleanup local artifacts to free VM disk\n",
        "            try:\n",
        "                if os.path.exists(local_src): os.remove(local_src)\n",
        "                if os.path.exists(wav_path): os.remove(wav_path)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] {file_rel}: {e}\")\n",
        "            # log the error for inspection\n",
        "            errfile = os.path.join(DATA_ROOT, 'features', 'errors.txt')\n",
        "            with open(errfile, 'a') as ef:\n",
        "                ef.write(f\"{file_rel}\\t{repr(e)}\\n\")\n",
        "\n",
        "    # advance to next batch\n",
        "    i += BATCH_SIZE\n",
        "    # brief cooldown\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"=== ALL BATCHES COMPLETE ===\")\n",
        "print(\"Features saved to:\", OUT_FEATURE_DIR)\n",
        "print(\"Processed count:\", len(processed_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBohg0kIL_8i"
      },
      "source": [
        "Building Dataset for ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1RkcXyBL42o",
        "outputId": "e35903be-626b-4239-dd9d-be94225b3a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading TRAIN split features...\n",
            "Loading features from: /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_train.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading train: 100%|██████████| 17948/17948 [58:24<00:00,  5.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading VAL split features...\n",
            "Loading features from: /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_val.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading val: 100%|██████████| 3846/3846 [12:50<00:00,  4.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading TEST split features...\n",
            "Loading features from: /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_test.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading test: 100%|██████████| 3847/3847 [12:36<00:00,  5.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing files (train/val/test): 0, 0, 0\n",
            "\n",
            "Shapes before scaling:\n",
            "X_train (17948, 119) y_train (17948,)\n",
            "X_val (3846, 119) y_val (3846,)\n",
            "X_test (3847, 119) y_test (3847,)\n",
            "\n",
            "Saved standardized datasets to: /content/drive/My Drive/Deep Fake Dataset/ml_ready_datasets\n",
            "train class balance: {np.int64(0): np.int64(9254), np.int64(1): np.int64(8694)}\n",
            "val class balance: {np.int64(0): np.int64(1983), np.int64(1): np.int64(1863)}\n",
            "test class balance: {np.int64(0): np.int64(1983), np.int64(1): np.int64(1864)}\n"
          ]
        }
      ],
      "source": [
        "# build full X/y matrices for train/val/test, standardize features (fit on train), and save to disk.\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib   # for saving scaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "META_DIR = os.path.join(DATA_ROOT, 'metadata_splits')\n",
        "FEATURE_ROOT = os.path.join(DATA_ROOT, 'features')\n",
        "OUT_DIR = os.path.join(DATA_ROOT, 'ml_ready_datasets')\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def flatten_features(npz_dict):\n",
        "    \"\"\"\n",
        "    Convert a dict loaded from .npz into a single flat 1D numpy array.\n",
        "    Preserves deterministic ordering by sorting keys alphabetically.\n",
        "    \"\"\"\n",
        "    flat_list = []\n",
        "    for key in sorted(npz_dict.keys()):\n",
        "        value = npz_dict[key]\n",
        "        arr = np.asarray(value).ravel()\n",
        "        flat_list.append(arr)\n",
        "    return np.concatenate(flat_list, axis=0)\n",
        "\n",
        "def load_split_to_Xy(split_csv, feature_subdir):\n",
        "    \"\"\"\n",
        "    Load all .npz features for the split described in split_csv.\n",
        "    Returns: X (n_samples x n_features), y (n_samples,), missing_list\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(split_csv)\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    missing = []\n",
        "    feat_dir = os.path.join(FEATURE_ROOT, feature_subdir)\n",
        "\n",
        "    print(f\"Loading features from: {split_csv}\")\n",
        "    for row in tqdm(df.itertuples(index=False), total=len(df), desc=f\"Loading {feature_subdir}\"):\n",
        "        file_rel = getattr(row, 'file_rel')\n",
        "        label = getattr(row, 'label')\n",
        "        stem = Path(file_rel).stem\n",
        "        feat_path = os.path.join(feat_dir, stem + '.npz')\n",
        "\n",
        "        if not os.path.exists(feat_path):\n",
        "            missing.append(stem)\n",
        "            continue\n",
        "\n",
        "        data = np.load(feat_path)\n",
        "        x_vec = flatten_features(data)\n",
        "        X_list.append(x_vec)\n",
        "        y_list.append(1 if label == 'fake' else 0)\n",
        "\n",
        "    if len(X_list) == 0:\n",
        "        return np.zeros((0,0)), np.array([]), missing\n",
        "\n",
        "    X = np.vstack(X_list)\n",
        "    y = np.array(y_list, dtype=np.int64)\n",
        "    return X, y, missing\n",
        "\n",
        "\n",
        "# Load splits\n",
        "train_csv = os.path.join(META_DIR, 'split_train.csv')\n",
        "val_csv   = os.path.join(META_DIR, 'split_val.csv')\n",
        "test_csv  = os.path.join(META_DIR, 'split_test.csv')\n",
        "\n",
        "print(\"Loading TRAIN split features...\")\n",
        "X_train, y_train, m_train = load_split_to_Xy(train_csv, 'train')\n",
        "print(\"Loading VAL split features...\")\n",
        "X_val,   y_val,   m_val   = load_split_to_Xy(val_csv, 'val')\n",
        "print(\"Loading TEST split features...\")\n",
        "X_test,  y_test,  m_test  = load_split_to_Xy(test_csv, 'test')\n",
        "\n",
        "print(f\"\\nMissing files (train/val/test): {len(m_train)}, {len(m_val)}, {len(m_test)}\")\n",
        "if len(m_train) + len(m_val) + len(m_test) > 0:\n",
        "    print(\"Example missing stems (up to 10):\", (m_train + m_val + m_test)[:10])\n",
        "\n",
        "print(\"\\nShapes before scaling:\")\n",
        "print(\"X_train\", X_train.shape, \"y_train\", y_train.shape)\n",
        "print(\"X_val\",   X_val.shape,   \"y_val\",   y_val.shape)\n",
        "print(\"X_test\",  X_test.shape,  \"y_test\",  y_test.shape)\n",
        "\n",
        "# Fit scaler on train and transform all splits\n",
        "scaler = StandardScaler()\n",
        "if X_train.size == 0:\n",
        "    raise RuntimeError(\"No train features found. Check feature files and paths.\")\n",
        "scaler.fit(X_train)\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_val_s   = scaler.transform(X_val)   if X_val.size else X_val\n",
        "X_test_s  = scaler.transform(X_test)  if X_test.size else X_test\n",
        "\n",
        "# Save standardized datasets and scaler\n",
        "np.savez_compressed(os.path.join(OUT_DIR, 'train.npz'), X=X_train_s, y=y_train)\n",
        "np.savez_compressed(os.path.join(OUT_DIR, 'val.npz'), X=X_val_s, y=y_val)\n",
        "np.savez_compressed(os.path.join(OUT_DIR, 'test.npz'), X=X_test_s, y=y_test)\n",
        "joblib.dump(scaler, os.path.join(OUT_DIR, 'scaler.joblib'))\n",
        "\n",
        "print(\"\\nSaved standardized datasets to:\", OUT_DIR)\n",
        "\n",
        "# Print class balance checks\n",
        "def print_balance(y, name):\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    print(f\"{name} class balance: {dict(zip(unique, counts))}\")\n",
        "\n",
        "print_balance(y_train, \"train\")\n",
        "print_balance(y_val, \"val\")\n",
        "print_balance(y_test, \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guc6hz6V93bi"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssgUj9LW94xs",
        "outputId": "db41b39d-c4f9-494c-fb2a-4ff2967bd807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (17948, 119) (17948,) (3846, 119) (3846,) (3847, 119) (3847,)\n",
            "Training logistic regression...\n",
            "\n",
            "--- VALIDATION Evaluation ---\n",
            "Accuracy:  0.7330\n",
            "Precision: 0.7294\n",
            "Recall:    0.7134\n",
            "F1 score:  0.7213\n",
            "ROC AUC:   0.8062\n",
            "Confusion matrix (tn, fp; fn, tp):\n",
            "[[1490  493]\n",
            " [ 534 1329]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7362    0.7514    0.7437      1983\n",
            "           1     0.7294    0.7134    0.7213      1863\n",
            "\n",
            "    accuracy                         0.7330      3846\n",
            "   macro avg     0.7328    0.7324    0.7325      3846\n",
            "weighted avg     0.7329    0.7330    0.7328      3846\n",
            "\n",
            "\n",
            "--- TEST (holdout) Evaluation ---\n",
            "Accuracy:  0.7169\n",
            "Precision: 0.7130\n",
            "Recall:    0.6958\n",
            "F1 score:  0.7043\n",
            "ROC AUC:   0.7932\n",
            "Confusion matrix (tn, fp; fn, tp):\n",
            "[[1461  522]\n",
            " [ 567 1297]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7204    0.7368    0.7285      1983\n",
            "           1     0.7130    0.6958    0.7043      1864\n",
            "\n",
            "    accuracy                         0.7169      3847\n",
            "   macro avg     0.7167    0.7163    0.7164      3847\n",
            "weighted avg     0.7168    0.7169    0.7168      3847\n",
            "\n",
            "\n",
            "Saved model to: /content/drive/My Drive/Deep Fake Dataset/models/logreg_baseline.joblib\n",
            "Saved metrics JSON to: /content/drive/My Drive/Deep Fake Dataset/models/logreg_baseline_metrics.json\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate a baseline Logistic Regression classifier\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import joblib\n",
        "\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "ML_READY_DIR = os.path.join(DATA_ROOT, 'ml_ready_datasets')\n",
        "OUT_MODEL_DIR = os.path.join(DATA_ROOT, 'models')\n",
        "os.makedirs(OUT_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# 1) Load standardized datasets\n",
        "train_npz = np.load(os.path.join(ML_READY_DIR, 'train.npz'))\n",
        "val_npz   = np.load(os.path.join(ML_READY_DIR, 'val.npz'))\n",
        "test_npz  = np.load(os.path.join(ML_READY_DIR, 'test.npz'))\n",
        "\n",
        "X_train = train_npz['X']\n",
        "y_train = train_npz['y']\n",
        "X_val   = val_npz['X']\n",
        "y_val   = val_npz['y']\n",
        "X_test  = test_npz['X']\n",
        "y_test  = test_npz['y']\n",
        "\n",
        "print(\"Shapes:\", X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "# 2) Create and fit the model\n",
        "model = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='saga',\n",
        "    max_iter=2000,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Training logistic regression...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 3) Evaluate on validation set\n",
        "def evaluate(model, X, y, prefix=\"\"):\n",
        "    probs = model.predict_proba(X)[:,1]   # probability of class=1 (fake)\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y, preds)\n",
        "    prec = precision_score(y, preds, zero_division=0)\n",
        "    rec = recall_score(y, preds, zero_division=0)\n",
        "    f1 = f1_score(y, preds, zero_division=0)\n",
        "    auc = roc_auc_score(y, probs)\n",
        "\n",
        "    cm = confusion_matrix(y, preds)  # [[tn, fp], [fn, tp]]\n",
        "    print(f\"\\n--- {prefix} Evaluation ---\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 score:  {f1:.4f}\")\n",
        "    print(f\"ROC AUC:   {auc:.4f}\")\n",
        "    print(\"Confusion matrix (tn, fp; fn, tp):\")\n",
        "    print(cm)\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(y, preds, digits=4))\n",
        "    return {'acc':acc, 'prec':prec, 'rec':rec, 'f1':f1, 'auc':auc, 'cm':cm}\n",
        "\n",
        "val_metrics = evaluate(model, X_val, y_val, prefix=\"VALIDATION\")\n",
        "\n",
        "# 4) Evaluate on test set\n",
        "test_metrics = evaluate(model, X_test, y_test, prefix=\"TEST (holdout)\")\n",
        "\n",
        "# 5) Save model and metrics\n",
        "model_path = os.path.join(OUT_MODEL_DIR, 'logreg_baseline.joblib')\n",
        "joblib.dump(model, model_path)\n",
        "print(\"\\nSaved model to:\", model_path)\n",
        "\n",
        "import json\n",
        "metrics_out = {\n",
        "    'val': {k: float(v) if not isinstance(v, (list, np.ndarray)) else None for k,v in val_metrics.items()},\n",
        "    'test': {k: float(v) if not isinstance(v, (list, np.ndarray)) else None for k,v in test_metrics.items()}\n",
        "}\n",
        "with open(os.path.join(OUT_MODEL_DIR, 'logreg_baseline_metrics.json'), 'w') as f:\n",
        "    json.dump(metrics_out, f, indent=2)\n",
        "\n",
        "print(\"Saved metrics JSON to:\", os.path.join(OUT_MODEL_DIR, 'logreg_baseline_metrics.json'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpYUQAFX-VvC"
      },
      "source": [
        "XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-3oCJ0W-JDp",
        "outputId": "132f7d93-994c-47ae-ae5e-467bdfe75d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training shapes: (17948, 119) (17948,)\n",
            "Training XGBoost...\n",
            "Done.\n",
            "\n",
            "--- VALIDATION Results ---\n",
            "Accuracy:  0.8157\n",
            "Precision: 0.7823\n",
            "Recall:    0.8583\n",
            "F1 score:  0.8185\n",
            "ROC AUC:   0.8963\n",
            "Confusion matrix:\n",
            "[[1538  445]\n",
            " [ 264 1599]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8535    0.7756    0.8127      1983\n",
            "           1     0.7823    0.8583    0.8185      1863\n",
            "\n",
            "    accuracy                         0.8157      3846\n",
            "   macro avg     0.8179    0.8169    0.8156      3846\n",
            "weighted avg     0.8190    0.8157    0.8155      3846\n",
            "\n",
            "\n",
            "--- TEST (holdout) Results ---\n",
            "Accuracy:  0.8113\n",
            "Precision: 0.7845\n",
            "Recall:    0.8417\n",
            "F1 score:  0.8121\n",
            "ROC AUC:   0.8939\n",
            "Confusion matrix:\n",
            "[[1552  431]\n",
            " [ 295 1569]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8403    0.7827    0.8104      1983\n",
            "           1     0.7845    0.8417    0.8121      1864\n",
            "\n",
            "    accuracy                         0.8113      3847\n",
            "   macro avg     0.8124    0.8122    0.8113      3847\n",
            "weighted avg     0.8133    0.8113    0.8113      3847\n",
            "\n",
            "\n",
            "Saved model to: /content/drive/My Drive/Deep Fake Dataset/models/xgboost_baseline.json\n",
            "Saved metrics to: /content/drive/My Drive/Deep Fake Dataset/models/xgboost_baseline_metrics.json\n"
          ]
        }
      ],
      "source": [
        "# XGBoost baseline classifier for deepfake audio features\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Build XGBoost model with baseline parameters\n",
        "model = XGBClassifier(\n",
        "    n_estimators=400,        # number of boosted trees\n",
        "    max_depth=6,            # depth per tree (controls complexity)\n",
        "    learning_rate=0.05,     # smaller → more stable boosting\n",
        "    subsample=0.8,          # row sampling (prevents overfitting)\n",
        "    colsample_bytree=0.8,   # column sampling\n",
        "    eval_metric='logloss',  # required to suppress warnings\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Training\n",
        "print(\"Training XGBoost...\")\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Evaluation helper function\n",
        "def evaluate(model, X, y, prefix=\"\"):\n",
        "    probs = model.predict_proba(X)[:,1]\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y, preds)\n",
        "    prec = precision_score(y, preds)\n",
        "    rec = recall_score(y, preds)\n",
        "    f1 = f1_score(y, preds)\n",
        "    auc = roc_auc_score(y, probs)\n",
        "    cm = confusion_matrix(y, preds)\n",
        "\n",
        "    print(f\"\\n--- {prefix} Results ---\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 score:  {f1:.4f}\")\n",
        "    print(f\"ROC AUC:   {auc:.4f}\")\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(cm)\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(y, preds, digits=4))\n",
        "\n",
        "    return dict(acc=acc, precision=prec, recall=rec, f1=f1, auc=auc)\n",
        "\n",
        "\n",
        "# Validation & Test Evaluation\n",
        "val_metrics  = evaluate(model, X_val,  y_val,  prefix=\"VALIDATION\")\n",
        "test_metrics = evaluate(model, X_test, y_test, prefix=\"TEST (holdout)\")\n",
        "\n",
        "\n",
        "# Save model + metrics\n",
        "model_path = os.path.join(OUT_MODEL_DIR, \"xgboost_baseline.json\")\n",
        "model.save_model(model_path)\n",
        "print(\"\\nSaved model to:\", model_path)\n",
        "\n",
        "import json\n",
        "metrics_path = os.path.join(OUT_MODEL_DIR, \"xgboost_baseline_metrics.json\")\n",
        "with open(metrics_path, 'w') as f:\n",
        "    json.dump({\"val\": val_metrics, \"test\": test_metrics}, f, indent=2)\n",
        "print(\"Saved metrics to:\", metrics_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiYF4Dk1A3LJ"
      },
      "source": [
        "XGBoost Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y45h9lwbGLW8",
        "outputId": "c26117c2-e2b2-4b99-c6a6-50d9326feb19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final model evaluation on TEST set:\n",
            "Accuracy: 0.8674291655835716\n",
            "Precision: 0.8464687819856704\n",
            "Recall: 0.8873390557939914\n",
            "F1: 0.8664222105814563\n",
            "ROC AUC: 0.9337315140063934\n",
            "Confusion matrix:\n",
            " [[1683  300]\n",
            " [ 210 1654]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8891    0.8487    0.8684      1983\n",
            "           1     0.8465    0.8873    0.8664      1864\n",
            "\n",
            "    accuracy                         0.8674      3847\n",
            "   macro avg     0.8678    0.8680    0.8674      3847\n",
            "weighted avg     0.8684    0.8674    0.8675      3847\n",
            "\n",
            "Saved booster to: /content/drive/My Drive/Deep Fake Dataset/models/xgb_booster_final.model\n",
            "Saved booster info JSON.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-656687125.py:40: UserWarning: [04:36:26] WARNING: /workspace/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
            "  booster.save_model(final_model_path)\n"
          ]
        }
      ],
      "source": [
        "# XGBoost: RandomizedSearchCV + Final Training + Evaluation\n",
        "import os, json, joblib\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import randint, uniform, loguniform\n",
        "\n",
        "# Config\n",
        "DATA_ROOT = Path('/content/drive/My Drive/Deep Fake Dataset')\n",
        "ML_READY_DIR = DATA_ROOT / 'ml_ready_datasets'\n",
        "OUT_MODEL_DIR = DATA_ROOT / 'models'\n",
        "SEARCH_DIR = DATA_ROOT / 'search_results'\n",
        "OUT_MODEL_DIR.mkdir(exist_ok=True)\n",
        "SEARCH_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "N_ITER, CV_FOLDS, RANDOM_SEED = 40, 3, 42\n",
        "NUM_BOOST_ROUND, EARLY_STOP = 500, 50\n",
        "\n",
        "# Load data\n",
        "train_npz, val_npz, test_npz = [np.load(ML_READY_DIR / f'{s}.npz') for s in ['train', 'val', 'test']]\n",
        "X_train, y_train = train_npz['X'], train_npz['y']\n",
        "X_val, y_val = val_npz['X'], val_npz['y']\n",
        "X_test, y_test = test_npz['X'], test_npz['y']\n",
        "print(f\"Shapes: {X_train.shape}, {X_val.shape}, {X_test.shape}\")\n",
        "\n",
        "# RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'max_depth': randint(3, 11),\n",
        "    'learning_rate': loguniform(0.01, 0.3),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.5, 0.5),\n",
        "    'min_child_weight': randint(1, 21),\n",
        "    'gamma': loguniform(1e-8, 10.0),\n",
        "    'reg_alpha': loguniform(1e-8, 10.0),\n",
        "    'reg_lambda': loguniform(1e-8, 10.0),\n",
        "    'n_estimators': randint(100, 501)\n",
        "}\n",
        "\n",
        "base_est = XGBClassifier(\n",
        "    objective='binary:logistic', tree_method='hist', use_label_encoder=False,\n",
        "    eval_metric='auc', n_jobs=-1, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
        "search = RandomizedSearchCV(\n",
        "    base_est, param_dist, n_iter=N_ITER, scoring='roc_auc', n_jobs=-1,\n",
        "    cv=cv, random_state=RANDOM_SEED, verbose=2, return_train_score=False\n",
        ")\n",
        "\n",
        "print(\"Starting RandomizedSearchCV...\")\n",
        "search.fit(X_train, y_train)\n",
        "print(f\"Search complete. Best CV ROC AUC: {search.best_score_:.4f}\")\n",
        "print(f\"Best params: {search.best_params_}\")\n",
        "\n",
        "# Save search results\n",
        "joblib.dump(search, SEARCH_DIR / f'xgb_random_search_{N_ITER}_iter.joblib')\n",
        "with open(SEARCH_DIR / f'xgb_random_search_{N_ITER}_iter_summary.json', 'w') as f:\n",
        "    json.dump({'best_params': search.best_params_, 'best_score_cv': float(search.best_score_)}, f, indent=2)\n",
        "\n",
        "# Final Training with xgb.train()\n",
        "best_params = {k: v.item() if hasattr(v, 'item') else v for k, v in search.best_params_.items()}\n",
        "\n",
        "# Prepare xgb.train() params (remove sklearn-only keys)\n",
        "xgb_params = {\n",
        "    'objective': 'binary:logistic', 'eval_metric': 'auc', 'tree_method': 'hist',\n",
        "    **{k: v for k, v in best_params.items()\n",
        "       if k not in {'n_estimators', 'use_label_encoder', 'verbosity', 'n_jobs', 'random_state'}}\n",
        "}\n",
        "num_boost_round = int(best_params.get('n_estimators', NUM_BOOST_ROUND))\n",
        "\n",
        "print(f\"\\nTraining final model with xgb.train() (num_boost_round={num_boost_round}, early_stop={EARLY_STOP})\")\n",
        "\n",
        "# Combine train+val\n",
        "X_combined = np.vstack([X_train, X_val])\n",
        "y_combined = np.concatenate([y_train, y_val])\n",
        "\n",
        "dtrain = xgb.DMatrix(X_combined, label=y_combined)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "booster = xgb.train(\n",
        "    xgb_params, dtrain, num_boost_round=num_boost_round,\n",
        "    evals=[(dtest, 'eval'), (dtrain, 'train')],\n",
        "    early_stopping_rounds=EARLY_STOP, verbose_eval=10\n",
        ")\n",
        "\n",
        "print(f\"Training finished. Best iteration: {booster.best_iteration}\")\n",
        "\n",
        "# Compatible Prediction + Evaluation\n",
        "# Try different prediction signatures for xgboost version compatibility\n",
        "try:\n",
        "    test_probs = booster.predict(dtest, ntree_limit=booster.best_iteration + 1)\n",
        "except TypeError:\n",
        "    try:\n",
        "        test_probs = booster.predict(dtest, iteration_range=(0, booster.best_iteration + 1))\n",
        "    except TypeError:\n",
        "        test_probs = booster.predict(dtest)\n",
        "\n",
        "test_preds = (test_probs >= 0.5).astype(int)\n",
        "\n",
        "print(f\"\\nTest Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, test_preds):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, test_preds):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, test_preds):.4f}\")\n",
        "print(f\"F1: {f1_score(y_test, test_preds):.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, test_probs):.4f}\")\n",
        "print(f\"Confusion matrix:\\n{confusion_matrix(y_test, test_preds)}\")\n",
        "print(f\"\\nClassification report:\\n{classification_report(y_test, test_preds, digits=4)}\")\n",
        "\n",
        "# Save final model and params\n",
        "booster.save_model(OUT_MODEL_DIR / 'xgb_booster_final.model')\n",
        "with open(OUT_MODEL_DIR / 'xgb_booster_final_params.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'xgb_params': xgb_params,\n",
        "        'num_boost_round': num_boost_round,\n",
        "        'best_iteration': int(booster.best_iteration)\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(f\"\\nSaved model: {OUT_MODEL_DIR / 'xgb_booster_final.model'}\")\n",
        "print(f\"Saved params: {OUT_MODEL_DIR / 'xgb_booster_final_params.json'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn3m9ze6QURz"
      },
      "source": [
        "Extracting Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrCcgg2yQVEC",
        "outputId": "25991ea9-7525-47f0-bebd-6d3d20e5af77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows in CSV: 3847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All files: 100%|██████████| 3847/3847 [1:19:51<00:00,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done. Processed: 3847 Errors: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os, time, traceback, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Config\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "SPLIT_CSV = os.path.join(DATA_ROOT, 'metadata_splits', 'split_test.csv')\n",
        "OUT_DIR = os.path.join(DATA_ROOT, 'embeddings', 'wav2vec2-base')\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "TARGET_SR = 16000\n",
        "CHUNK_SEC = 60\n",
        "LIMIT = None\n",
        "N_RETRIES = 3\n",
        "\n",
        "import warnings\n",
        "\n",
        "def load_audio_safe(path, sr=TARGET_SR):\n",
        "    \"\"\"\n",
        "    Loads audio and returns (y, sr).\n",
        "    Defensive: if caller expects a single return, always return a tuple.\n",
        "    \"\"\"\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", message=\"PySoundFile failed. Trying audioread instead.\")\n",
        "        warnings.filterwarnings(\"ignore\", module=\"librosa\")\n",
        "        y, orig_sr = librosa.load(path, sr=None, mono=True)\n",
        "    if y is None:\n",
        "        raise RuntimeError(f\"librosa.load returned None for {path}\")\n",
        "    if orig_sr != sr:\n",
        "        try:\n",
        "            y = librosa.resample(y, orig_sr, sr)\n",
        "        except Exception as e:\n",
        "            # provide a helpful error\n",
        "            raise RuntimeError(f\"Resample failed for {path}: {e}\")\n",
        "    # ensure numpy array float32\n",
        "    y = np.asarray(y, dtype=np.float32)\n",
        "    return y, sr\n",
        "\n",
        "def chunks_from_audio_safe(y, sr=TARGET_SR, chunk_sec=CHUNK_SEC):\n",
        "    \"\"\"\n",
        "    Yield (start, end, chunk_array) robustly.\n",
        "    Accepts scalars/None and converts them to empty arrays gracefully.\n",
        "    \"\"\"\n",
        "    if y is None:\n",
        "        return\n",
        "    # If y is accidentally non-iterable, try to coerce\n",
        "    if not hasattr(y, '__len__'):\n",
        "        # e.g., int or float — coerce to single-element array\n",
        "        try:\n",
        "            y = np.array([y], dtype=np.float32)\n",
        "        except Exception:\n",
        "            # give up\n",
        "            return\n",
        "    # now y is array-like\n",
        "    n = len(y)\n",
        "    if n == 0:\n",
        "        return\n",
        "    chunk_len = int(chunk_sec * sr)\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        j = min(i + chunk_len, n)\n",
        "        yield i, j, y[i:j]\n",
        "        i = j\n",
        "\n",
        "def embed_audio_array_safe(y, sr=TARGET_SR):\n",
        "    \"\"\"\n",
        "    Robust wrapper around the model embedding logic. Returns (mean_vec, std_vec).\n",
        "    \"\"\"\n",
        "    # defensive: ensure y is an ndarray\n",
        "    if y is None:\n",
        "        d = model.config.hidden_size\n",
        "        return np.zeros(d, dtype=np.float32), np.zeros(d, dtype=np.float32)\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 0:\n",
        "        # scalar -> convert to 1-d array\n",
        "        y = y.reshape(1)\n",
        "    if y.size == 0:\n",
        "        d = model.config.hidden_size\n",
        "        return np.zeros(d, dtype=np.float32), np.zeros(d, dtype=np.float32)\n",
        "\n",
        "    chunk_means = []\n",
        "    chunk_stds = []\n",
        "    chunk_weights = []\n",
        "\n",
        "    for start, end, chunk in chunks_from_audio_safe(y, sr=sr, chunk_sec=CHUNK_SEC):\n",
        "        # chunk should be numpy array\n",
        "        chunk = np.asarray(chunk, dtype=np.float32)\n",
        "        if chunk.size == 0:\n",
        "            continue\n",
        "        # processor expects Python list or numpy array; pass as list is safer for very short arrays\n",
        "        try:\n",
        "            inputs = processor(chunk, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
        "            input_values = inputs.input_values.to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(input_values).last_hidden_state\n",
        "            out = out.squeeze(0).cpu().numpy()\n",
        "            if out.ndim == 1:\n",
        "                # single time-step -> convert to (1, D)\n",
        "                out = out.reshape(1, -1)\n",
        "            mean_vec = out.mean(axis=0)\n",
        "            std_vec = out.std(axis=0)\n",
        "            chunk_means.append(mean_vec)\n",
        "            chunk_stds.append(std_vec)\n",
        "            chunk_weights.append(chunk.size)\n",
        "        except Exception as e:\n",
        "            # If embedding this chunk fails, print debug and skip chunk\n",
        "            print(f\"  WARNING: embedding chunk [{start}:{end}] failed (size={chunk.size}): {e}\")\n",
        "            continue\n",
        "\n",
        "    if len(chunk_means) == 0:\n",
        "        d = model.config.hidden_size\n",
        "        return np.zeros(d, dtype=np.float32), np.zeros(d, dtype=np.float32)\n",
        "\n",
        "    chunk_means = np.vstack(chunk_means)\n",
        "    chunk_stds = np.vstack(chunk_stds)\n",
        "    weights = np.array(chunk_weights, dtype=np.float32)\n",
        "    if weights.sum() == 0:\n",
        "        weights = np.ones(len(chunk_means), dtype=np.float32) / len(chunk_means)\n",
        "    else:\n",
        "        weights = weights / weights.sum()\n",
        "\n",
        "    mean_global = np.average(chunk_means, axis=0, weights=weights).astype(np.float32)\n",
        "    std_global  = np.average(chunk_stds, axis=0, weights=weights).astype(np.float32)\n",
        "    return mean_global, std_global\n",
        "\n",
        "# Drive-safe save helper (ensure uses local tmp + move)\n",
        "def safe_save_embedding_drive(out_path_drive, mean_vec, std_vec, tmp_local_dir=\"/content\", tmp_suffix=\".tmp.npz\"):\n",
        "    tmp_local_path = os.path.join(tmp_local_dir, Path(out_path_drive).stem + tmp_suffix)\n",
        "    np.savez_compressed(tmp_local_path, wav2vec2_mean=mean_vec.astype(np.float32), wav2vec2_std=std_vec.astype(np.float32))\n",
        "    try:\n",
        "        shutil.move(tmp_local_path, out_path_drive)\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            shutil.copyfile(tmp_local_path, out_path_drive)\n",
        "            os.remove(tmp_local_path)\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"Failed to move/copy tmp embedding to Drive: {e} / {e2}\")\n",
        "\n",
        "# Main loop\n",
        "import pandas as pd\n",
        "df = pd.read_csv(SPLIT_CSV)\n",
        "rows = list(df.itertuples(index=False))\n",
        "n_total = len(rows)\n",
        "print(\"Total rows in CSV:\", n_total)\n",
        "\n",
        "processed_log = os.path.join(OUT_DIR, f\"processed_wav2vec2_{Path(SPLIT_CSV).stem}.txt\")\n",
        "processed = set()\n",
        "if os.path.exists(processed_log):\n",
        "    with open(processed_log, \"r\") as f:\n",
        "        for line in f:\n",
        "            s = line.strip()\n",
        "            if s:\n",
        "                processed.add(s)\n",
        "\n",
        "count = 0\n",
        "errors = []\n",
        "for r in tqdm(rows, total=n_total, desc=\"All files\"):\n",
        "    if LIMIT is not None and count >= LIMIT:\n",
        "        break\n",
        "    file_rel = getattr(r, \"file_rel\")\n",
        "    stem = Path(file_rel).stem\n",
        "    out_path = os.path.join(OUT_DIR, stem + \".npz\")\n",
        "    if stem in processed or os.path.exists(out_path):\n",
        "        continue\n",
        "\n",
        "    src_path = getattr(r, \"filepath\")\n",
        "    ok = False\n",
        "    last_err = None\n",
        "    for attempt in range(1, N_RETRIES+1):\n",
        "        try:\n",
        "            # load audio (returns tuple)\n",
        "            y, sr = load_audio_safe(src_path, sr=TARGET_SR)\n",
        "            # Defensive check - if y is an int or similar, log and coerce\n",
        "            if not hasattr(y, '__len__'):\n",
        "                print(f\"  NOTE: audio for {stem} was scalar; coercing to array\")\n",
        "                y = np.array([y], dtype=np.float32)\n",
        "            # embed\n",
        "            mean_vec, std_vec = embed_audio_array_safe(y, sr=sr)\n",
        "            # save\n",
        "            safe_save_embedding_drive(out_path, mean_vec, std_vec)\n",
        "            # log\n",
        "            with open(processed_log, \"a\") as f:\n",
        "                f.write(stem + \"\\n\")\n",
        "            processed.add(stem)\n",
        "            ok = True\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            tb = traceback.format_exc()\n",
        "            print(f\"[Attempt {attempt}] Error processing {stem}: {e}\")\n",
        "            print(tb)\n",
        "            time.sleep(0.5 * attempt)\n",
        "    if not ok:\n",
        "        errors.append((stem, str(last_err)))\n",
        "    count += 1\n",
        "\n",
        "print(\"Done. Processed:\", len(processed), \"Errors:\", len(errors))\n",
        "if errors:\n",
        "    print(\"Sample errors:\", errors[:20])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW4BvhgJ5PbK"
      },
      "source": [
        "Training XGBoost model with original features + embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWjSLx0q5NfK",
        "outputId": "7c0f0c2a-93b9-4887-d82c-ad45a19189d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N_JOBS: 2\n",
            "Copying /content/drive/My Drive/Deep Fake Dataset/features -> /content/features (this may take a minute)...\n"
          ]
        }
      ],
      "source": [
        "# PREPARE DATASET FOR ML\n",
        "\n",
        "import os, shutil, time, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# config\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "META_DIR = os.path.join(DATA_ROOT, 'metadata_splits')\n",
        "FEATURE_DIR_DRIVE = os.path.join(DATA_ROOT, 'features')             # drive\n",
        "EMBED_DIR_DRIVE   = os.path.join(DATA_ROOT, 'embeddings', 'wav2vec2-base')\n",
        "LOCAL_FEATURE_DIR = '/content/features'    # local copy target\n",
        "LOCAL_EMBED_DIR   = '/content/embeddings'\n",
        "OUT_ML_DIR = os.path.join(DATA_ROOT, 'ml_ready_with_embeddings')   # output on Drive\n",
        "os.makedirs(OUT_ML_DIR, exist_ok=True)\n",
        "\n",
        "# tuning\n",
        "N_JOBS = min(8, (os.cpu_count() or 4))   # threads for I/O; adjust as needed\n",
        "LIMIT = None   # set small int for prototype, e.g. 500; None => run all\n",
        "VERBOSE = True\n",
        "\n",
        "print(\"N_JOBS:\", N_JOBS)\n",
        "t_all_start = time.time()\n",
        "\n",
        "# 1) copy to local if not present (do once)\n",
        "def copy_if_missing(src, dst):\n",
        "    if os.path.exists(dst):\n",
        "        print(f\"Local copy exists: {dst} (skipping copy)\")\n",
        "        return\n",
        "    print(f\"Copying {src} -> {dst} (this may take a minute)...\")\n",
        "    shutil.copytree(src, dst)\n",
        "    print(\"Copy done.\")\n",
        "\n",
        "if not os.path.exists(LOCAL_FEATURE_DIR):\n",
        "    copy_if_missing(FEATURE_DIR_DRIVE, LOCAL_FEATURE_DIR)\n",
        "else:\n",
        "    print(\"LOCAL_FEATURE_DIR already present; skipping copy.\")\n",
        "\n",
        "if not os.path.exists(LOCAL_EMBED_DIR):\n",
        "    copy_if_missing(EMBED_DIR_DRIVE, LOCAL_EMBED_DIR)\n",
        "else:\n",
        "    print(\"LOCAL_EMBED_DIR already present; skipping copy.\")\n",
        "\n",
        "# helper: deterministic flatten of an npz\n",
        "def flatten_npz_to_vector(npz_obj):\n",
        "    keys = sorted(list(npz_obj.keys()))\n",
        "    parts = []\n",
        "    for k in keys:\n",
        "        v = np.asarray(npz_obj[k]).ravel()\n",
        "        parts.append(v)\n",
        "    if len(parts) == 0:\n",
        "        return np.zeros((0,), dtype=np.float32)\n",
        "    return np.concatenate(parts).astype(np.float32)\n",
        "\n",
        "# helper to find one existing sample to determine dims\n",
        "def find_sample_paths(split_csv, feature_subdir, local_feature_dir=LOCAL_FEATURE_DIR, local_embed_dir=LOCAL_EMBED_DIR):\n",
        "    df = pd.read_csv(split_csv)\n",
        "    for r in df.itertuples(index=False):\n",
        "        stem = Path(r.file_rel).stem\n",
        "        # Construct feature path using the provided feature_subdir\n",
        "        cand = os.path.join(local_feature_dir, feature_subdir, stem + '.npz')\n",
        "        emb = os.path.join(local_embed_dir, stem + '.npz')\n",
        "        if os.path.exists(cand) and os.path.exists(emb):\n",
        "            return cand, emb\n",
        "    return None, None\n",
        "\n",
        "# compute dims for a split\n",
        "def compute_flat_dim(sample_feat_npz, sample_emb_npz):\n",
        "    f = np.load(sample_feat_npz)\n",
        "    e = np.load(sample_emb_npz)\n",
        "    v1 = flatten_npz_to_vector(f)\n",
        "    # embedding prefer mean+std keys\n",
        "    emb_parts = []\n",
        "    if 'wav2vec2_mean' in e:\n",
        "        emb_parts.append(np.asarray(e['wav2vec2_mean']).ravel())\n",
        "    if 'wav2vec2_std' in e:\n",
        "        emb_parts.append(np.asarray(e['wav2vec2_std']).ravel())\n",
        "    if len(emb_parts) == 0:\n",
        "        emb_vec = flatten_npz_to_vector(e)\n",
        "    else:\n",
        "        emb_vec = np.concatenate(emb_parts).astype(np.float32)\n",
        "    return v1.shape[0] + emb_vec.shape[0]\n",
        "\n",
        "# loader for a single row\n",
        "def load_and_flatten_row(row, feature_subdir, local_feature_dir=LOCAL_FEATURE_DIR, local_embed_dir=LOCAL_EMBED_DIR):\n",
        "    stem = Path(row.file_rel).stem\n",
        "    # Construct feature path using the provided feature_subdir\n",
        "    hand_path = os.path.join(local_feature_dir, feature_subdir, stem + '.npz')\n",
        "    emb_path = os.path.join(local_embed_dir, stem + '.npz')\n",
        "    if (not os.path.exists(hand_path)) or (not os.path.exists(emb_path)):\n",
        "        return (stem, None, None, f\"missing hand or embed: hand={hand_path}, emb={emb_path}\")\n",
        "    try:\n",
        "        hand = np.load(hand_path)\n",
        "        hand_vec = flatten_npz_to_vector(hand)\n",
        "        emb = np.load(emb_path)\n",
        "        emb_parts = []\n",
        "        if 'wav2vec2_mean' in emb:\n",
        "            emb_parts.append(np.asarray(emb['wav2vec2_mean']).ravel())\n",
        "        if 'wav2vec2_std' in emb:\n",
        "            emb_parts.append(np.asarray(emb['wav2vec2_std']).ravel())\n",
        "        if len(emb_parts) == 0:\n",
        "            emb_vec = flatten_npz_to_vector(emb)\n",
        "        else:\n",
        "            emb_vec = np.concatenate(emb_parts).astype(np.float32)\n",
        "        x = np.concatenate([hand_vec, emb_vec]).astype(np.float32)\n",
        "        y = 1 if row.label == 'fake' else 0\n",
        "        return (stem, x, y, None)\n",
        "    except Exception as e:\n",
        "        return (stem, None, None, repr(e))\n",
        "\n",
        "# process one split: returns X,y,missing_list\n",
        "def process_split(split_csv, feature_subdir, limit=None):\n",
        "    df = pd.read_csv(split_csv)\n",
        "    if limit:\n",
        "        df = df.iloc[:limit]\n",
        "    total = len(df)\n",
        "    print(f\"\\nProcessing split {split_csv} -> {total} rows\")\n",
        "    # find sample dims\n",
        "    sample_feat, sample_emb = find_sample_paths(split_csv, feature_subdir)\n",
        "    if not sample_feat:\n",
        "        raise RuntimeError(f\"Could not find any sample .npz files locally for {feature_subdir} split. Check LOCAL dirs.\")\n",
        "    dim = compute_flat_dim(sample_feat, sample_emb)\n",
        "    print(\"Detected flattened feature dimension:\", dim)\n",
        "    # preallocate\n",
        "    X = np.zeros((total, dim), dtype=np.float32)\n",
        "    y = np.zeros((total,), dtype=np.int64)\n",
        "    missing = []\n",
        "    # prepare rows list for parallel processing\n",
        "    rows = list(df.itertuples(index=False))\n",
        "    # parallel load\n",
        "    results = Parallel(n_jobs=N_JOBS, backend=\"threading\")(\n",
        "        delayed(load_and_flatten_row)(r, feature_subdir, LOCAL_FEATURE_DIR, LOCAL_EMBED_DIR) for r in tqdm(rows)\n",
        "    )\n",
        "    filled = 0\n",
        "    for i, res in enumerate(results):\n",
        "        stem, xvec, lab, err = res\n",
        "        if xvec is None:\n",
        "            missing.append((stem, err))\n",
        "            continue\n",
        "        # place into preallocated slot i\n",
        "        L = xvec.shape[0]\n",
        "        X[filled, :L] = xvec # Use 'filled' instead of 'i' as missing rows are skipped\n",
        "        y[filled] = lab      # Use 'filled' instead of 'i'\n",
        "        filled += 1\n",
        "    print(f\"Filled {filled}/{total} rows; missing {len(missing)}\")\n",
        "    return X[:filled], y[:filled], missing # Return only the filled part of X and y\n",
        "\n",
        "# process train/val/test\n",
        "t0 = time.time()\n",
        "train_csv = os.path.join(META_DIR, 'split_train.csv')\n",
        "val_csv   = os.path.join(META_DIR, 'split_val.csv')\n",
        "test_csv  = os.path.join(META_DIR, 'split_test.csv')\n",
        "\n",
        "X_train, y_train, miss_train = process_split(train_csv, 'train', limit=LIMIT)\n",
        "X_val,   y_val,   miss_val   = process_split(val_csv, 'val', limit=LIMIT)\n",
        "X_test,  y_test,  miss_test  = process_split(test_csv, 'test', limit=LIMIT)\n",
        "\n",
        "print(\"\\nMissing counts (train/val/test):\", len(miss_train), len(miss_val), len(miss_test))\n",
        "print(\"Shapes before scaling:\", X_train.shape, X_val.shape, X_test.shape)\n",
        "\n",
        "# Standardize (fit scaler on train only)\n",
        "scaler = StandardScaler()\n",
        "# Ensure X_train is not empty before fitting\n",
        "if X_train.size == 0:\n",
        "    raise RuntimeError(\"X_train is empty. Cannot fit scaler.\")\n",
        "scaler.fit(X_train)\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_val_s   = scaler.transform(X_val)   if X_val.size > 0 else X_val.reshape(0, X_train_s.shape[1])\n",
        "X_test_s  = scaler.transform(X_test)  if X_test.size > 0 else X_test.reshape(0, X_train_s.shape[1])\n",
        "\n",
        "# Save to Drive\n",
        "np.savez_compressed(os.path.join(OUT_ML_DIR, 'train.npz'), X=X_train_s, y=y_train)\n",
        "np.savez_compressed(os.path.join(OUT_ML_DIR, 'val.npz'),   X=X_val_s,   y=y_val)\n",
        "np.savez_compressed(os.path.join(OUT_ML_DIR, 'test.npz'),  X=X_test_s,  y=y_test)\n",
        "joblib.dump(scaler, os.path.join(OUT_ML_DIR, 'scaler.joblib'))\n",
        "\n",
        "t_all_end = time.time()\n",
        "print(\"\\nSaved ML-ready datasets to:\", OUT_ML_DIR)\n",
        "print(\"Total time (s):\", round(t_all_end - t_all_start, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "B1h1gBD86Kdd",
        "outputId": "3812b799-526d-4cac-84f1-ac95c6a7064f"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3777623316.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train XGBoost classifier on combined features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracker\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m from .core import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/tracker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LIB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_jcargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m from ._data_utils import (\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mCategories\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mTransformedDf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/_data_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mNumpyOrCupy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_cupy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_pyarrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy_isinstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# sklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sklearn_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mXGBModelBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifierMixin\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mXGBClassifierBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_arraylike_not_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_numpy_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preserve_dia_indices_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0m_NUMPY_NAMESPACE_NAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array_api_compat.numpy\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mArrowDtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mvalue_counts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooleanDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m from pandas.core.arrays.floating import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/arrays/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowExtensionArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from pandas.core.arrays.base import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mExtensionArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mExtensionOpsMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mExtensionScalarOpsMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/arrays/arrow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.arrays.arrow.accessors import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mListAccessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mStructAccessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowExtensionArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/arrays/arrow/accessors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpa_version_under10p1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/compute.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m \u001b[0m_make_global_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/compute.py\u001b[0m in \u001b[0;36m_make_global_functions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcpp_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/compute.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(name, func)\u001b[0m\n\u001b[1;32m    302\u001b[0m     wrapper.__signature__ = _make_signature(arg_names, var_arg_names,\n\u001b[1;32m    303\u001b[0m                                             options_class)\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorate_compute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/compute.py\u001b[0m in \u001b[0;36m_decorate_compute_function\u001b[0;34m(wrapper, exposed_name, func, options_class)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# 3b. Compute function option values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptions_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0moptions_class_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_scrape_options_class_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptions_class_doc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptions_class_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/compute.py\u001b[0m in \u001b[0;36m_scrape_options_class_doc\u001b[0;34m(options_class)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocscrape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumpyDocString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_OptionsClassDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/vendored/docscrape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, docstring, config)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/vendored/docscrape.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m             if section in ('Parameters', 'Other Parameters', 'Attributes',\n\u001b[1;32m    410\u001b[0m                            'Methods'):\n\u001b[0;32m--> 411\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_param_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Returns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Yields'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Raises'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Warns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Receives'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 self[section] = self._parse_param_list(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/vendored/docscrape.py\u001b[0m in \u001b[0;36m_parse_param_list\u001b[0;34m(self, content, single_element_is_type)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parse_param_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_element_is_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdedent_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/vendored/docscrape.py\u001b[0m in \u001b[0;36mdedent_lines\u001b[0;34m(lines)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdedent_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;34m\"\"\"Deindent a list of lines maximally\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtextwrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/textwrap.py\u001b[0m in \u001b[0;36mdedent\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0mmargin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_whitespace_only_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0mindents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_leading_whitespace_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmargin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train XGBoost classifier on combined features\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Config\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "ML_READY_DIR = os.path.join(DATA_ROOT, 'ml_ready_with_embeddings')\n",
        "OUT_MODEL_DIR = os.path.join(DATA_ROOT, 'models')\n",
        "os.makedirs(OUT_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Load the standardized datasets and scaler\n",
        "print(\"Loading ML-ready datasets...\")\n",
        "train_npz = np.load(os.path.join(ML_READY_DIR, 'train.npz'))\n",
        "val_npz   = np.load(os.path.join(ML_READY_DIR, 'val.npz'))\n",
        "test_npz  = np.load(os.path.join(ML_READY_DIR, 'test.npz'))\n",
        "\n",
        "X_train_s = train_npz['X']\n",
        "y_train = train_npz['y']\n",
        "X_val_s   = val_npz['X']\n",
        "y_val   = val_npz['y']\n",
        "X_test_s  = test_npz['X']\n",
        "y_test  = test_npz['y']\n",
        "\n",
        "scaler = joblib.load(os.path.join(ML_READY_DIR, 'scaler.joblib'))\n",
        "\n",
        "print(\"Data loaded. Shapes:\")\n",
        "print(f\"X_train_s: {X_train_s.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"X_val_s:   {X_val_s.shape}, y_val:   {y_val.shape}\")\n",
        "print(f\"X_test_s:  {X_test_s.shape}, y_test:  {y_test.shape}\")\n",
        "\n",
        "#defaut params = best params from CV\n",
        "best_params = {'colsample_bytree': np.float64(0.776382483417745),\n",
        "                'gamma': np.float64(0.0014145953382213344),\n",
        "                'learning_rate': np.float64(0.2805876934404873),\n",
        "                'max_depth': 6,\n",
        "                'min_child_weight': 1,\n",
        "                'n_estimators': 355,\n",
        "                'reg_alpha': np.float64(0.0002330874380942336),\n",
        "                'reg_lambda': np.float64(2.2603818105733772e-05),\n",
        "                'subsample': np.float64(0.7578765867237889),\n",
        "                'use_label_encoder': False,\n",
        "                'objective': 'binary:logistic',\n",
        "                'n_jobs': -1,\n",
        "                'random_state': 42,\n",
        "                'tree_method': 'hist',\n",
        "                'eval_metric': 'auc'\n",
        "}\n",
        "\n",
        "# Ensure classifier-friendly params: remove sklearn-disallowed keys if any\n",
        "clf_params = best_params.copy()\n",
        "# remove any keys that XGBClassifier won't accept directly (rare)\n",
        "for bad in ['verbosity', 'eval_metric']:\n",
        "    if bad in clf_params:\n",
        "        clf_params.pop(bad)\n",
        "\n",
        "print(\"\\nFinal params for XGBClassifier:\")\n",
        "print({k: clf_params[k] for k in ['n_estimators','max_depth','learning_rate'] if k in clf_params})\n",
        "\n",
        "clf = XGBClassifier(**clf_params)\n",
        "print(\"Training XGBoost on combined features... (may take a few minutes)\")\n",
        "clf.fit(X_train_s, y_train)  # no early stopping here to avoid API mismatches\n",
        "\n",
        "# Save final model and params\n",
        "model_path = os.path.join(OUT_MODEL_DIR, 'xgb_combined_final_IGNORE.joblib')\n",
        "joblib.dump(clf, model_path)\n",
        "with open(os.path.join(OUT_MODEL_DIR, 'xgb_combined_final_params_IGNORE.json'), 'w') as f:\n",
        "    json.dump(clf_params, f, indent=2)\n",
        "print(\"\\nSaved XGBoost model to:\", model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPkciuJiWdWL",
        "outputId": "768e3dcc-1185-42e2-9c7d-a838cf4190b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- VALIDATION Evaluation ---\n",
            "Accuracy:  0.9253770150806032\n",
            "Precision: 0.9169312169312169\n",
            "Recall:    0.9302200751476114\n",
            "F1 score:  0.9235278443911538\n",
            "ROC AUC:   0.980955404892201\n",
            "Confusion matrix (tn, fp; fn, tp):\n",
            "[[1826  157]\n",
            " [ 130 1733]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9335    0.9208    0.9271      1983\n",
            "           1     0.9169    0.9302    0.9235      1863\n",
            "\n",
            "    accuracy                         0.9254      3846\n",
            "   macro avg     0.9252    0.9255    0.9253      3846\n",
            "weighted avg     0.9255    0.9254    0.9254      3846\n",
            "\n",
            "\n",
            "--- TEST (holdout) Evaluation ---\n",
            "Accuracy:  0.9347543540421107\n",
            "Precision: 0.929217668972858\n",
            "Recall:    0.9366952789699571\n",
            "F1 score:  0.9329414907827945\n",
            "ROC AUC:   0.9839983745960839\n",
            "Confusion matrix (tn, fp; fn, tp):\n",
            "[[1850  133]\n",
            " [ 118 1746]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9400    0.9329    0.9365      1983\n",
            "           1     0.9292    0.9367    0.9329      1864\n",
            "\n",
            "    accuracy                         0.9348      3847\n",
            "   macro avg     0.9346    0.9348    0.9347      3847\n",
            "weighted avg     0.9348    0.9348    0.9348      3847\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on val and test\n",
        "def eval_and_print(model, Xv, yv, setname):\n",
        "    probs = model.predict_proba(Xv)[:,1]\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "    print(f\"\\n--- {setname} Evaluation ---\")\n",
        "    print(\"Accuracy: \", accuracy_score(yv, preds))\n",
        "    print(\"Precision:\", precision_score(yv, preds))\n",
        "    print(\"Recall:   \", recall_score(yv, preds))\n",
        "    print(\"F1 score: \", f1_score(yv, preds))\n",
        "    print(\"ROC AUC:  \", roc_auc_score(yv, probs))\n",
        "    print(\"Confusion matrix (tn, fp; fn, tp):\")\n",
        "    print(confusion_matrix(yv, preds))\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(yv, preds, digits=4))\n",
        "\n",
        "eval_and_print(clf, X_val_s, y_val, \"VALIDATION\")\n",
        "eval_and_print(clf, X_test_s, y_test, \"TEST (holdout)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7CqdfexztSw"
      },
      "outputs": [],
      "source": [
        "#Cross-validation to tune hyperparameters of combined model; using HalvingRandomSearchCV\n",
        "import os, time, json, joblib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "\n",
        "# config\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "OUT_MODEL_DIR = os.path.join(DATA_ROOT, 'models')\n",
        "os.makedirs(OUT_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# load data\n",
        "ML_DIR = os.path.join(DATA_ROOT, 'ml_ready_embeddings_only')\n",
        "train_npz = np.load(os.path.join(ML_DIR, 'train.npz'))\n",
        "val_npz   = np.load(os.path.join(ML_DIR, 'val.npz'))\n",
        "test_npz  = np.load(os.path.join(ML_DIR, 'test.npz'))\n",
        "X_train, y_train = train_npz['X'], train_npz['y']\n",
        "X_val, y_val     = val_npz['X'], val_npz['y']\n",
        "X_test, y_test   = test_npz['X'], test_npz['y']\n",
        "\n",
        "# Halving parameters\n",
        "RANDOM_STATE = 42\n",
        "CV = 3\n",
        "N_JOBS = -1\n",
        "SCORING = 'roc_auc'\n",
        "MAX_RESOURCES = 400   # maximum n_estimators budget\n",
        "FACTOR = 3             # promotion factor\n",
        "VERBOSE = 3            # higher = more info printed\n",
        "N_CANDIDATES = 60      # number of random candidates to sample initially (larger -> more exploration)\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "tree_method = 'hist'\n",
        "\n",
        "fixed_params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'use_label_encoder': False,\n",
        "    'eval_metric': 'auc',\n",
        "    'n_jobs': -1,\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'tree_method': tree_method\n",
        "}\n",
        "\n",
        "# Parameter distributions\n",
        "param_dist = {\n",
        "    'max_depth': randint(3, 12),\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'subsample': uniform(0.5, 0.5),\n",
        "    'colsample_bytree': uniform(0.4, 0.6),\n",
        "    'min_child_weight': randint(1, 10),\n",
        "    'gamma': uniform(0.0, 1.0),\n",
        "    'reg_alpha': uniform(0.0, 1.0),\n",
        "    'reg_lambda': uniform(0.0, 1.0)\n",
        "}\n",
        "\n",
        "# Build base estimator\n",
        "base_clf = XGBClassifier(**fixed_params)\n",
        "\n",
        "# Build HalvingRandomSearchCV\n",
        "halver = HalvingRandomSearchCV(\n",
        "    estimator=base_clf,\n",
        "    param_distributions=param_dist,\n",
        "    factor=FACTOR,\n",
        "    resource='n_estimators',\n",
        "    max_resources=MAX_RESOURCES,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=N_JOBS,\n",
        "    verbose=VERBOSE,\n",
        "    cv=CV,\n",
        "    scoring=SCORING,\n",
        "    error_score='raise',\n",
        "    n_candidates=N_CANDIDATES\n",
        ")\n",
        "\n",
        "\n",
        "# fit halving search\n",
        "halver.fit(X_train, y_train)\n",
        "\n",
        "# Save the halver object and best params\n",
        "joblib_path = os.path.join(OUT_MODEL_DIR, f\"xgb_halving_search_{N_CANDIDATES}.joblib\")\n",
        "joblib.dump(halver, joblib_path)\n",
        "print(\"Saved halving search object to:\", joblib_path)\n",
        "\n",
        "best_params = halver.best_params_\n",
        "# normalize numpy types\n",
        "for k,v in list(best_params.items()):\n",
        "    try:\n",
        "        if hasattr(v,'item'):\n",
        "            best_params[k] = v.item()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "with open(os.path.join(OUT_MODEL_DIR, 'xgb_best_halving_params.json'), 'w') as f:\n",
        "    json.dump(best_params, f, indent=2)\n",
        "print(\"Best params saved to xgb_best_halving_params.json\")\n",
        "print(\"Best CV score:\", halver.best_score_)\n",
        "print(\"Best params:\", best_params)\n",
        "\n",
        "# Train final model on train+val with the best params\n",
        "print(\"\\nTraining final model on train+val with best params (n_estimators scaled to a larger final budget)...\")\n",
        "final_params = fixed_params.copy(); final_params.update(best_params)\n",
        "final_params['n_estimators'] = max(final_params.get('n_estimators', 200), 1000)\n",
        "print(\"Final model params (summary):\", {k: final_params[k] for k in ['n_estimators','learning_rate','max_depth'] if k in final_params})\n",
        "clf_final = XGBClassifier(**final_params)\n",
        "X_comb = np.vstack([X_train, X_val]); y_comb = np.concatenate([y_train, y_val])\n",
        "clf_final.fit(X_comb, y_comb)\n",
        "\n",
        "\n",
        "# Evaluate on test\n",
        "y_prob_test = clf_final.predict_proba(X_test)[:,1]\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "y_pred_test = (y_prob_test >= 0.5).astype(int)\n",
        "print(\"\\n--- TEST EVAL ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_test))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_test))\n",
        "\n",
        "# Save final model\n",
        "joblib.dump(clf_final, os.path.join(OUT_MODEL_DIR, 'xgb_combined_halving_final.joblib'))\n",
        "print(\"Saved final model to models/xgb_combined_halving_final.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "ADpW2CVBXA8h",
        "outputId": "bfb2aafc-cf55-48f2-d7cc-043307e4e828"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix plot saved to: /content/drive/My Drive/Deep Fake Dataset/models/test_confusion_matrix_audio.svg\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels, title='Confusion Matrix', filename='confusion_matrix.png', format='png'):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    save_path = os.path.join(OUT_MODEL_DIR, filename)\n",
        "    plt.savefig(save_path, format=format)\n",
        "    plt.show()\n",
        "    print(f\"Confusion matrix plot saved to: {save_path}\")\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test_prob = clf.predict_proba(X_test_s)[:, 1]\n",
        "y_pred_test_class = (y_pred_test_prob >= 0.5).astype(int)\n",
        "\n",
        "# Plot for the test set\n",
        "plot_confusion_matrix(\n",
        "    y_test,\n",
        "    y_pred_test_class,\n",
        "    labels=['Real', 'Fake'],\n",
        "    title='Confusion Matrix For Audio Classification (Combined Features)',\n",
        "    filename='test_confusion_matrix_audio.svg',\n",
        "    format='svg'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWd3YeFky6ld"
      },
      "source": [
        "Conducting Inference (In Preparation for Multimodal Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOhJWXKeyrA5"
      },
      "outputs": [],
      "source": [
        "# Predict on X_train_s / X_val_s / X_test_s, save CSVs, and optionally filter by modify_audio==modify_video\n",
        "\n",
        "import os, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "# config\n",
        "DRIVE_ROOT = Path('/content/drive/My Drive/Deep Fake Dataset')\n",
        "ML_READY_DIR = DRIVE_ROOT / 'ml_ready_with_embeddings'\n",
        "META_SPLITS_DIR = DRIVE_ROOT / 'metadata_splits'\n",
        "MODEL_PRIMARY = DRIVE_ROOT / 'models' / 'xgb_combined_final.joblib'\n",
        "MODEL_FALLBACK = DRIVE_ROOT / 'models' / 'xgb_combined_final_IGNORE.joblib'\n",
        "OUT_DIR = DRIVE_ROOT / 'predictions_from_embeddings_only'\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "SPLITS_INFO = {\n",
        "    'train': {'X_var': 'X_train_s', 'y_var': 'y_train', 'npz': ML_READY_DIR / 'train.npz', 'meta_csv': META_SPLITS_DIR / 'split_train.csv'},\n",
        "    'val':   {'X_var': 'X_val_s',   'y_var': 'y_val',   'npz': ML_READY_DIR / 'val.npz',   'meta_csv': META_SPLITS_DIR / 'split_val.csv'},\n",
        "    'test':  {'X_var': 'X_test_s',  'y_var': 'y_test',  'npz': ML_READY_DIR / 'test.npz',  'meta_csv': META_SPLITS_DIR / 'split_test.csv'}\n",
        "}\n",
        "\n",
        "DEFAULT_THRESHOLD = 0.2\n",
        "VERBOSE = True\n",
        "\n",
        "def vprint(*a, **kw):\n",
        "    if VERBOSE:\n",
        "        print(*a, **kw)\n",
        "\n",
        "# helper label parser\n",
        "def parse_label_to_int(x):\n",
        "    if pd.isna(x) or x is None:\n",
        "        return None\n",
        "    if isinstance(x, (int, np.integer)):\n",
        "        return int(x)\n",
        "    if isinstance(x, float):\n",
        "        if np.isnan(x): return None\n",
        "        return int(x)\n",
        "    s = str(x).strip().lower()\n",
        "    if s in ('fake','1','true','t','yes','y'):\n",
        "        return 1\n",
        "    if s in ('real','0','false','f','no','n'):\n",
        "        return 0\n",
        "    try:\n",
        "        fx = float(s)\n",
        "        if np.isnan(fx): return None\n",
        "        return int(fx)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Load model (prefer primary)\n",
        "model_path = MODEL_PRIMARY if MODEL_PRIMARY.exists() else (MODEL_FALLBACK if MODEL_FALLBACK.exists() else None)\n",
        "if model_path is None:\n",
        "    raise FileNotFoundError(f\"No model found. Checked:\\n - {MODEL_PRIMARY}\\n - {MODEL_FALLBACK}\\nPlease point MODEL_PRIMARY to your saved joblib model.\")\n",
        "vprint(\"Loading model from:\", model_path)\n",
        "model = joblib.load(str(model_path))\n",
        "\n",
        "# Utility: get prob for \"fake\" class from predict_proba (robust to class ordering)\n",
        "def prob_fake_from_proba(proba_arr):\n",
        "    \"\"\"\n",
        "    proba_arr: shape (1, C) or (C,) predicted probabilities\n",
        "    returns float prob of positive class (interpreted as 'fake').\n",
        "    \"\"\"\n",
        "    probs = np.asarray(proba_arr)\n",
        "    if probs.ndim == 1:\n",
        "        # single-dim: either (C,) or (N,) - assume (C,) for single sample\n",
        "        if probs.shape[0] == 1:\n",
        "            return float(probs.ravel()[0])\n",
        "        else:\n",
        "            # ambiguous, fallback to last column\n",
        "            return float(probs.ravel()[-1])\n",
        "    # if model has classes_ try to locate 1/'fake'; otherwise take last column\n",
        "    if hasattr(model, 'classes_'):\n",
        "        classes = list(model.classes_)\n",
        "        for candidate in (1, '1', 'fake', 'Fake', 'FAKE'):\n",
        "            if candidate in classes:\n",
        "                idx = classes.index(candidate)\n",
        "                return float(probs[0, idx])\n",
        "    # fallback to second column if binary, else last\n",
        "    if probs.shape[1] >= 2:\n",
        "        return float(probs[0, 1])\n",
        "    return float(probs[0, -1])\n",
        "\n",
        "# Prepare summary\n",
        "summary = {}\n",
        "\n",
        "# Loop splits\n",
        "for split, info in SPLITS_INFO.items():\n",
        "    vprint(f\"\\n=== Split: {split} ===\")\n",
        "    # load X,y from memory if present; else load from npz\n",
        "    X = globals().get(info['X_var'], None)\n",
        "    y = globals().get(info['y_var'], None)\n",
        "    if X is None or y is None:\n",
        "        npz_path = info['npz']\n",
        "        if not npz_path.exists():\n",
        "            vprint(f\"ML-ready npz for split {split} not found at {npz_path}; skipping split.\")\n",
        "            continue\n",
        "        data = np.load(npz_path, allow_pickle=True)\n",
        "        # heuristics: prefer X key\n",
        "        if 'X' in data:\n",
        "            X = data['X']\n",
        "            y = data['y'] if 'y' in data else None\n",
        "        else:\n",
        "            keys = list(data.keys())\n",
        "            X = data[keys[0]]\n",
        "            y = data[keys[1]] if len(keys) > 1 else None\n",
        "        vprint(f\"Loaded {npz_path.name}: X.shape {X.shape}, y present: {y is not None}\")\n",
        "\n",
        "    # ensure numpy array\n",
        "    X = np.asarray(X)\n",
        "    y_arr = np.asarray(y) if y is not None else None\n",
        "\n",
        "    # predict for all rows in X\n",
        "    n = X.shape[0]\n",
        "    preds = []\n",
        "    for i in range(n):\n",
        "        xi = X[i].reshape(1, -1)\n",
        "        # predict_proba preferred\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            try:\n",
        "                proba = model.predict_proba(xi)\n",
        "                prob_fake = prob_fake_from_proba(proba)\n",
        "            except Exception as e:\n",
        "                # fallback to predict\n",
        "                predv = model.predict(xi)\n",
        "                prob_fake = float(predv[0])\n",
        "        else:\n",
        "            predv = model.predict(xi)\n",
        "            prob_fake = float(predv[0])\n",
        "        pred_default = int(prob_fake >= DEFAULT_THRESHOLD)\n",
        "        preds.append({'ml_index': int(i), 'prob_fake': float(prob_fake), 'pred_default': pred_default})\n",
        "\n",
        "    df_preds = pd.DataFrame(preds)\n",
        "\n",
        "    # If metadata CSV present and matches X length, attach metadata\n",
        "    meta_csv = info.get('meta_csv', None)\n",
        "    attached_meta = False\n",
        "    if meta_csv is not None and meta_csv.exists():\n",
        "        meta_df = pd.read_csv(meta_csv)\n",
        "        if len(meta_df) == n:\n",
        "            vprint(\"Metadata CSV matches X length; attaching metadata columns (file_rel, modify_audio, modify_video).\")\n",
        "            meta_df = meta_df.reset_index().rename(columns={'index': 'ml_index'})  # ml_index = row index\n",
        "            # attach relevant columns\n",
        "            merge_cols = ['ml_index','file_rel']\n",
        "            for c in ('modify_audio','modify_video','duration','n_fakes','label'):\n",
        "                if c in meta_df.columns:\n",
        "                    merge_cols.append(c)\n",
        "            # drop duplicates if any and merge\n",
        "            meta_subset = meta_df[merge_cols].copy()\n",
        "            df_preds = df_preds.merge(meta_subset, on='ml_index', how='left')\n",
        "            attached_meta = True\n",
        "        else:\n",
        "            vprint(f\"WARNING: metadata CSV rows ({len(meta_df)}) != X rows ({n}). Skipping metadata attach for split {split}.\")\n",
        "    else:\n",
        "        vprint(\"No metadata CSV found for split\", split, \"at\", meta_csv, \"; saving predictions without metadata.\")\n",
        "\n",
        "    # Save predictions CSV\n",
        "    out_csv = OUT_DIR / f\"mlready_predictions_{split}.csv\"\n",
        "    df_preds.to_csv(out_csv, index=False)\n",
        "    vprint(\"Saved predictions:\", out_csv, \"rows:\", len(df_preds))\n",
        "\n",
        "    # Compute metrics using y array (if available)\n",
        "    metrics = {}\n",
        "    if y_arr is not None:\n",
        "        y_true = np.asarray(y_arr).astype(int)\n",
        "        y_pred = df_preds['pred_default'].astype(int).values\n",
        "        # Ensure length alignment\n",
        "        if len(y_true) != len(y_pred):\n",
        "            vprint(f\"WARNING: y length ({len(y_true)}) != predictions length ({len(y_pred)}). Truncating to min length.\")\n",
        "            mlen = min(len(y_true), len(y_pred))\n",
        "            y_true = y_true[:mlen]\n",
        "            y_pred = y_pred[:mlen]\n",
        "            df_preds = df_preds.iloc[:mlen].reset_index(drop=True)\n",
        "        try:\n",
        "            prob_array = df_preds['prob_fake'].astype(float).values\n",
        "            roc_auc = roc_auc_score(y_true, prob_array) if len(np.unique(y_true))>1 else None\n",
        "        except Exception:\n",
        "            roc_auc = None\n",
        "        metrics['n_examples'] = int(len(y_true))\n",
        "        metrics['accuracy'] = float(accuracy_score(y_true, y_pred))\n",
        "        metrics['precision'] = float(precision_score(y_true, y_pred, zero_division=0))\n",
        "        metrics['recall'] = float(recall_score(y_true, y_pred, zero_division=0))\n",
        "        metrics['f1'] = float(f1_score(y_true, y_pred, zero_division=0))\n",
        "        metrics['roc_auc'] = float(roc_auc) if roc_auc is not None else None\n",
        "        metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred).tolist()\n",
        "        vprint(\"Metrics (using ML-ready y labels):\", metrics)\n",
        "    else:\n",
        "        vprint(\"No y available in ML-ready for split\", split, \"- skipping metrics against ground truth y.\")\n",
        "\n",
        "    # If metadata attached, create filtered CSV where modify_audio == modify_video and compute accuracy on that subset\n",
        "    filtered_count = None\n",
        "    filtered_acc = None\n",
        "    if attached_meta and ('modify_audio' in df_preds.columns) and ('modify_video' in df_preds.columns):\n",
        "        mask = df_preds['modify_audio'].notnull() & df_preds['modify_video'].notnull() & (df_preds['modify_audio'] == df_preds['modify_video'])\n",
        "        df_filtered = df_preds[mask].copy()\n",
        "        out_filt = OUT_DIR / f\"mlready_predictions_{split}_modalitymatched2.csv\"\n",
        "        df_filtered.to_csv(out_filt, index=False)\n",
        "        filtered_count = int(len(df_filtered))\n",
        "        vprint(f\"Saved filtered modality-matched CSV: {out_filt} rows: {filtered_count}\")\n",
        "        # compute accuracy using modify_audio as ground truth, if parseable\n",
        "        df_filtered['y_true_meta'] = df_filtered['modify_audio'].apply(parse_label_to_int)\n",
        "        valid = df_filtered[df_filtered['y_true_meta'].notnull()].copy()\n",
        "        if len(valid) > 0:\n",
        "            y_true_meta = valid['y_true_meta'].astype(int).values\n",
        "            y_pred_meta = valid['pred_default'].astype(int).values\n",
        "            filtered_acc = float(accuracy_score(y_true_meta, y_pred_meta))\n",
        "            vprint(f\"Accuracy on filtered rows (modify_audio == modify_video) for split {split}: {filtered_acc:.4f} (n={len(valid)})\")\n",
        "        else:\n",
        "            vprint(\"No parseable modify_audio labels in filtered set to compute accuracy.\")\n",
        "    else:\n",
        "        vprint(\"Metadata not attached or modify flags missing; skipping modality filtering for split\", split)\n",
        "\n",
        "    # Save per-split summary\n",
        "    summary = {\n",
        "        'n_predictions': int(len(df_preds)),\n",
        "        'metrics_vs_mlready_y': metrics if metrics else None,\n",
        "        'filtered_n': filtered_count,\n",
        "        'filtered_accuracy': filtered_acc,\n",
        "        'predictions_csv': str(out_csv),\n",
        "        'filtered_csv': str(out_filt) if ('out_filt' in locals() and 'df_filtered' in locals()) else None\n",
        "    }\n",
        "    summary_path = OUT_DIR / f\"summary_{split}.json\"\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    vprint(\"Saved summary for split\", split, \"->\", summary_path)\n",
        "\n",
        "vprint(\"\\nAll splits processed. CSVs and summaries are in:\", OUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6H20XMr4xeq",
        "outputId": "f8de5d1f-a7ad-4eda-ddee-03be74afff6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Deep Fake Dataset/predictions_from_mlready_arrays/mlready_predictions_val_modalitymatched2.csv\n",
            "Loading /content/drive/My Drive/Deep Fake Dataset/predictions_from_mlready_arrays/mlready_predictions_test_modalitymatched2.csv\n",
            "Combined 1992 rows from validation and 1976 rows from test into 3968 rows.\n",
            "Combined predictions saved to: /content/drive/My Drive/Deep Fake Dataset/predictions_from_mlready_arrays/predictions_audio_FINAL2.csv\n"
          ]
        }
      ],
      "source": [
        "# Combine modality matched test/val sets into final dataset for multimodal training\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Define paths\n",
        "DRIVE_ROOT = Path('/content/drive/My Drive/Deep Fake Dataset')\n",
        "PREDICTIONS_DIR = DRIVE_ROOT / 'predictions_from_mlready_arrays'\n",
        "\n",
        "# Input CSV files\n",
        "val_predictions_path = PREDICTIONS_DIR / 'mlready_predictions_val_modalitymatched2.csv'\n",
        "test_predictions_path = PREDICTIONS_DIR / 'mlready_predictions_test_modalitymatched2.csv'\n",
        "\n",
        "# Output combined CSV file\n",
        "combined_predictions_path = PREDICTIONS_DIR / 'predictions_audio_FINAL2.csv'\n",
        "\n",
        "# Load the predictions into pandas DataFrames\n",
        "print(f\"Loading {val_predictions_path}\")\n",
        "df_val_predictions = pd.read_csv(val_predictions_path)\n",
        "\n",
        "print(f\"Loading {test_predictions_path}\")\n",
        "df_test_predictions = pd.read_csv(test_predictions_path)\n",
        "\n",
        "# Combine the DataFrames\n",
        "df_combined_predictions = pd.concat([df_val_predictions, df_test_predictions], ignore_index=True)\n",
        "\n",
        "# Save the combined DataFrame to a new CSV file\n",
        "df_combined_predictions.to_csv(combined_predictions_path, index=False)\n",
        "\n",
        "print(f\"Combined {len(df_val_predictions)} rows from validation and {len(df_test_predictions)} rows from test into {len(df_combined_predictions)} rows.\")\n",
        "print(f\"Combined predictions saved to: {combined_predictions_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3iCE5uXym0X"
      },
      "outputs": [],
      "source": [
        "#Evaluate accuracy on modality matched data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Define paths\n",
        "DRIVE_ROOT = Path('/content/drive/My Drive/Deep Fake Dataset')\n",
        "PREDICTIONS_DIR = DRIVE_ROOT / 'predictions_from_mlready_arrays'\n",
        "OUT_MODEL_DIR = DRIVE_ROOT / 'models'\n",
        "\n",
        "# Load the final sampled predictions CSV\n",
        "sampled_predictions_path = PREDICTIONS_DIR / 'mlready_predictions_test_modalitymatched2.csv'\n",
        "print(f\"Loading sampled predictions from: {sampled_predictions_path}\")\n",
        "df_predictions = pd.read_csv(sampled_predictions_path)\n",
        "\n",
        "# Filter data to keep only rows where modify_audio == modify_video\n",
        "# 'modify_audio' and 'modify_video' are boolean, and 'pred_default' is 0/1 int\n",
        "df_filtered = df_predictions[df_predictions['modify_audio'] == df_predictions['modify_video']].copy()\n",
        "\n",
        "print(f\"Original samples: {len(df_predictions)}\")\n",
        "print(f\"Filtered samples (modify_audio == modify_video): {len(df_filtered)}\")\n",
        "\n",
        "# Create the 'y_true_filtered' and 'y_pred_filtered' columns within df_filtered\n",
        "# 'modify_audio' (True/False) is cast to 1/0 for true labels\n",
        "df_filtered['y_true_filtered'] = df_filtered['modify_audio'].astype(int);\n",
        "# 'pred_default' (0/1) directly serves as predicted labels\n",
        "df_filtered['y_pred_filtered'] = df_filtered['pred_default'].astype(int)\n",
        "\n",
        "# Function for plotting confusion matrix (pasted from prev code)\n",
        "def plot_confusion_matrix(y_true, y_pred, labels, title='Confusion Matrix', filename='confusion_matrix.png', format='png'):\n",
        "    cm = confusion_matrix(y_true, y_pred);\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    save_path = os.path.join(OUT_MODEL_DIR, filename)\n",
        "    plt.savefig(save_path, format=format)\n",
        "    plt.show()\n",
        "    print(f\"Confusion matrix plot saved to: {save_path}\")\n",
        "\n",
        "# Generate and plot the confusion matrix for the filtered data\n",
        "plot_confusion_matrix(\n",
        "    df_filtered['y_true_filtered'],\n",
        "    df_filtered['y_pred_filtered'],\n",
        "    labels=['Real', 'Fake'],\n",
        "    title='Confusion Matrix For Classification With Matched Samples (Combined Features)',\n",
        "    filename='confusion_matrix_modality_matched_audio.svg', # Changed filename extension\n",
        "    format='svg' # Added format parameter\n",
        ")\n",
        "\n",
        "# Print accuracy for the filtered subset\n",
        "filtered_accuracy = accuracy_score(df_filtered['y_true_filtered'], df_filtered['y_pred_filtered'])\n",
        "print(f\"Accuracy on filtered data (modify_audio == modify_video): {filtered_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urZPKPSkCVYd"
      },
      "source": [
        "Ablation Study: Embeddings Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeLzSO5bCWnB",
        "outputId": "3fe43d78-db20-4e5d-ac0f-c6a75df9a9f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N_JOBS: 2\n",
            "Copying /content/drive/My Drive/Deep Fake Dataset/embeddings/wav2vec2-base -> /content/embeddings_only (this may take several minutes)...\n",
            "Copy done.\n",
            "\n",
            "Processing split /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_train.csv -> 17948 rows\n",
            "Detected embedding vector dimension: 1536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17948/17948 [00:21<00:00, 847.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filled 17948/17948 rows; missing 0\n",
            "\n",
            "Processing split /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_val.csv -> 3846 rows\n",
            "Detected embedding vector dimension: 1536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3846/3846 [00:04<00:00, 799.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filled 3846/3846 rows; missing 0\n",
            "\n",
            "Processing split /content/drive/My Drive/Deep Fake Dataset/metadata_splits/split_test.csv -> 3847 rows\n",
            "Detected embedding vector dimension: 1536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3847/3847 [00:05<00:00, 680.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filled 3847/3847 rows; missing 0\n",
            "\n",
            "Missing (train/val/test): 0 0 0\n",
            "Shapes before scaling:\n",
            "  X_train: (17948, 1536)\n",
            "  X_val:   (3846, 1536)\n",
            "  X_test:  (3847, 1536)\n",
            "\n",
            "Scaling (fit on train only)...\n",
            "\n",
            "=== DONE ===\n",
            "Saved embeddings-only ML datasets to: /content/drive/My Drive/Deep Fake Dataset/ml_ready_embeddings_only\n",
            "Total time: 821.7 seconds\n"
          ]
        }
      ],
      "source": [
        "#Building ML dataset using only embeddigns as features\n",
        "\n",
        "import os, shutil, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# configs\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "META_DIR = os.path.join(DATA_ROOT, 'metadata_splits')\n",
        "EMBED_DIR_DRIVE   = os.path.join(DATA_ROOT, 'embeddings', 'wav2vec2-base')\n",
        "LOCAL_EMBED_DIR   = '/content/embeddings_only'\n",
        "OUT_ML_DIR = os.path.join(DATA_ROOT, 'ml_ready_embeddings_only')\n",
        "os.makedirs(OUT_ML_DIR, exist_ok=True)\n",
        "\n",
        "# threading\n",
        "N_JOBS = min(8, (os.cpu_count() or 4))\n",
        "LIMIT = None\n",
        "VERBOSE = True\n",
        "\n",
        "t_all_start = time.time()\n",
        "\n",
        "# 1) copy embeddings folder locally (fast I/O)\n",
        "def copy_if_missing(src, dst):\n",
        "    if os.path.exists(dst):\n",
        "        print(f\"Local copy exists: {dst} (skipping copy)\")\n",
        "        return\n",
        "    print(f\"Copying {src} -> {dst} (this may take several minutes)...\")\n",
        "    shutil.copytree(src, dst)\n",
        "    print(\"Copy done.\")\n",
        "\n",
        "copy_if_missing(EMBED_DIR_DRIVE, LOCAL_EMBED_DIR)\n",
        "\n",
        "# helpers\n",
        "\n",
        "def flatten_embedding_npz(npz_obj):\n",
        "    \"\"\"\n",
        "    Prefer wav2vec2_mean + wav2vec2_std (best signal).\n",
        "    Fallback: flatten all keys.\n",
        "    \"\"\"\n",
        "    if 'wav2vec2_mean' in npz_obj and 'wav2vec2_std' in npz_obj:\n",
        "        mean_v = np.asarray(npz_obj['wav2vec2_mean']).ravel()\n",
        "        std_v  = np.asarray(npz_obj['wav2vec2_std']).ravel()\n",
        "        return np.concatenate([mean_v, std_v]).astype(np.float32)\n",
        "    else:\n",
        "        keys = sorted(list(npz_obj.keys()))\n",
        "        parts = [np.asarray(npz_obj[k]).ravel() for k in keys]\n",
        "        return np.concatenate(parts).astype(np.float32)\n",
        "\n",
        "# Find one sample to detect embedding dimensionality\n",
        "def find_embedding_sample(split_csv, local_embed_dir=LOCAL_EMBED_DIR):\n",
        "    df = pd.read_csv(split_csv)\n",
        "    for r in df.itertuples(index=False):\n",
        "        stem = Path(r.file_rel).stem\n",
        "        emb = os.path.join(local_embed_dir, stem + '.npz')\n",
        "        if os.path.exists(emb):\n",
        "            return emb\n",
        "    return None\n",
        "\n",
        "def compute_embed_dim(emb_path):\n",
        "    d = np.load(emb_path)\n",
        "    v = flatten_embedding_npz(d)\n",
        "    return v.shape[0]\n",
        "\n",
        "# parallel worker\n",
        "def load_embed_row(row, local_embed_dir=LOCAL_EMBED_DIR):\n",
        "    stem = Path(row.file_rel).stem\n",
        "    emb_path = os.path.join(local_embed_dir, stem + '.npz')\n",
        "    if not os.path.exists(emb_path):\n",
        "        return (stem, None, None, \"missing embedding\")\n",
        "    try:\n",
        "        d = np.load(emb_path)\n",
        "        x = flatten_embedding_npz(d)\n",
        "        y = 1 if row.label == 'fake' else 0\n",
        "        return (stem, x, y, None)\n",
        "    except Exception as e:\n",
        "        return (stem, None, None, str(e))\n",
        "\n",
        "# Process split\n",
        "def process_split(split_csv, limit=None):\n",
        "    df = pd.read_csv(split_csv)\n",
        "    if limit:\n",
        "        df = df.iloc[:limit]\n",
        "    total = len(df)\n",
        "\n",
        "    print(f\"\\nProcessing split {split_csv} -> {total} rows\")\n",
        "\n",
        "    # detect dim\n",
        "    emb_sample = find_embedding_sample(split_csv)\n",
        "    if not emb_sample:\n",
        "        raise RuntimeError(\"No embedding file found for split: \" + split_csv)\n",
        "    dim = compute_embed_dim(emb_sample)\n",
        "    print(\"Detected embedding vector dimension:\", dim)\n",
        "\n",
        "    # preallocate\n",
        "    X = np.zeros((total, dim), dtype=np.float32)\n",
        "    y = np.zeros((total,), dtype=np.int64)\n",
        "    missing = []\n",
        "\n",
        "    rows = list(df.itertuples(index=False))\n",
        "\n",
        "    results = Parallel(n_jobs=N_JOBS, backend=\"threading\")(\n",
        "        delayed(load_embed_row)(r, LOCAL_EMBED_DIR) for r in tqdm(rows)\n",
        "    )\n",
        "\n",
        "    filled = 0\n",
        "    for stem, xvec, lab, err in results:\n",
        "        if xvec is None:\n",
        "            missing.append((stem, err))\n",
        "            continue\n",
        "        X[filled, :xvec.shape[0]] = xvec\n",
        "        y[filled] = lab\n",
        "        filled += 1\n",
        "\n",
        "    print(f\"Filled {filled}/{total} rows; missing {len(missing)}\")\n",
        "    return X[:filled], y[:filled], missing\n",
        "\n",
        "# BUILD SPLITS\n",
        "\n",
        "train_csv = os.path.join(META_DIR, 'split_train.csv')\n",
        "val_csv   = os.path.join(META_DIR, 'split_val.csv')\n",
        "test_csv  = os.path.join(META_DIR, 'split_test.csv')\n",
        "\n",
        "X_train, y_train, miss_train = process_split(train_csv, limit=LIMIT)\n",
        "X_val,   y_val,   miss_val   = process_split(val_csv,   limit=LIMIT)\n",
        "X_test,  y_test,  miss_test  = process_split(test_csv,  limit=LIMIT)\n",
        "\n",
        "print(\"\\nMissing (train/val/test):\", len(miss_train), len(miss_val), len(miss_test))\n",
        "print(\"Shapes before scaling:\")\n",
        "print(\"  X_train:\", X_train.shape)\n",
        "print(\"  X_val:  \", X_val.shape)\n",
        "print(\"  X_test: \", X_test.shape)\n",
        "\n",
        "# SCALE\n",
        "\n",
        "print(\"\\nScaling (fit on train only)...\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "if X_train.size == 0:\n",
        "    raise RuntimeError(\"No training data!\")\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_val_s   = scaler.transform(X_val)\n",
        "X_test_s  = scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(scaler, os.path.join(OUT_ML_DIR, 'scaler_embeddings_only.joblib'))\n",
        "\n",
        "# SAVE\n",
        "\n",
        "np.savez_compressed(os.path.join(OUT_ML_DIR, 'train.npz'), X=X_train_s, y=y_train)\n",
        "np.savez_compressed(os.path.join(OUT_ML_DIR, 'val.npz'),   X=X_val_s,   y=y_val)\n",
        "np.savez_compressed(os.path.join(OUT_ML_DIR, 'test.npz'),  X=X_test_s,  y=y_test)\n",
        "\n",
        "t2 = time.time()\n",
        "print(\"\\n=== DONE ===\")\n",
        "print(\"Saved embeddings-only ML datasets to:\", OUT_ML_DIR)\n",
        "print(\"Total time:\", round(t2 - t_all_start, 1), \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbOUKfxqS5P5",
        "outputId": "2902a4c1-0a81-440b-a0e4-f7fb73d8ffde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ML-ready datasets...\n",
            "Data loaded. Shapes:\n",
            "X_train_s: (17948, 1536), y_train: (17948,)\n",
            "X_val_s:   (3846, 1536), y_val:   (3846,)\n",
            "X_test_s:  (3847, 1536), y_test:  (3847,)\n",
            "\n",
            "Final params for XGBClassifier:\n",
            "{'n_estimators': 355, 'max_depth': 6, 'learning_rate': np.float64(0.2805876934404873)}\n",
            "Training XGBoost on combined features... (may take a few minutes)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [00:14:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- VALIDATION Evaluation ---\n",
            "Accuracy:  0.9191367654706188\n",
            "Precision: 0.9114528101802757\n",
            "Recall:    0.9227053140096618\n",
            "F1 score:  0.9170445452120566\n",
            "ROC AUC:   0.9778587667746971\n",
            "Confusion matrix (tn, fp; fn, tp):\n",
            "[[1816  167]\n",
            " [ 144 1719]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9265    0.9158    0.9211      1983\n",
            "           1     0.9115    0.9227    0.9170      1863\n",
            "\n",
            "    accuracy                         0.9191      3846\n",
            "   macro avg     0.9190    0.9192    0.9191      3846\n",
            "weighted avg     0.9192    0.9191    0.9191      3846\n",
            "\n",
            "\n",
            "--- TEST (holdout) Evaluation ---\n",
            "Accuracy:  0.9264361840395113\n",
            "Precision: 0.9184753838009528\n",
            "Recall:    0.930793991416309\n",
            "F1 score:  0.924593658406608\n",
            "ROC AUC:   0.9809978162016626\n",
            "Confusion matrix (tn, fp; fn, tp):\n",
            "[[1829  154]\n",
            " [ 129 1735]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9341    0.9223    0.9282      1983\n",
            "           1     0.9185    0.9308    0.9246      1864\n",
            "\n",
            "    accuracy                         0.9264      3847\n",
            "   macro avg     0.9263    0.9266    0.9264      3847\n",
            "weighted avg     0.9265    0.9264    0.9264      3847\n",
            "\n",
            "\n",
            "Saved XGBoost model to: /content/drive/My Drive/Deep Fake Dataset/models/xgb_combined_final.joblib\n"
          ]
        }
      ],
      "source": [
        "# Train XGBoost classifier on embeddings only\n",
        "from xgboost import XGBClassifier\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Define paths (if not already defined in this cell or implicitly available)\n",
        "DATA_ROOT = '/content/drive/My Drive/Deep Fake Dataset'\n",
        "ML_READY_DIR = os.path.join(DATA_ROOT, 'ml_ready_embeddings_only')\n",
        "OUT_MODEL_DIR = os.path.join(DATA_ROOT, 'models')\n",
        "os.makedirs(OUT_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Load the standardized datasets and scaler\n",
        "print(\"Loading ML-ready datasets...\")\n",
        "train_npz = np.load(os.path.join(ML_READY_DIR, 'train.npz'))\n",
        "val_npz   = np.load(os.path.join(ML_READY_DIR, 'val.npz'))\n",
        "test_npz  = np.load(os.path.join(ML_READY_DIR, 'test.npz'))\n",
        "\n",
        "X_train_s = train_npz['X']\n",
        "y_train = train_npz['y']\n",
        "X_val_s   = val_npz['X']\n",
        "y_val   = val_npz['y']\n",
        "X_test_s  = test_npz['X']\n",
        "y_test  = test_npz['y']\n",
        "\n",
        "scaler = joblib.load(os.path.join(ML_READY_DIR, 'scaler_embeddings_only.joblib'))\n",
        "\n",
        "print(\"Data loaded. Shapes:\")\n",
        "print(f\"X_train_s: {X_train_s.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"X_val_s:   {X_val_s.shape}, y_val:   {y_val.shape}\")\n",
        "print(f\"X_test_s:  {X_test_s.shape}, y_test:  {y_test.shape}\")\n",
        "\n",
        "#defaut params = best params from CV\n",
        "best_params = {'colsample_bytree': np.float64(0.776382483417745),\n",
        "                'gamma': np.float64(0.0014145953382213344),\n",
        "                'learning_rate': np.float64(0.2805876934404873),\n",
        "                'max_depth': 6,\n",
        "                'min_child_weight': 1,\n",
        "                'n_estimators': 355,\n",
        "                'reg_alpha': np.float64(0.0002330874380942336),\n",
        "                'reg_lambda': np.float64(2.2603818105733772e-05),\n",
        "                'subsample': np.float64(0.7578765867237889),\n",
        "                'use_label_encoder': False,\n",
        "                'objective': 'binary:logistic',\n",
        "                'n_jobs': -1,\n",
        "                'random_state': 42,\n",
        "                'tree_method': 'hist',\n",
        "                'eval_metric': 'auc'\n",
        "}\n",
        "\n",
        "clf_params = best_params.copy()\n",
        "# remove any keys that XGBClassifier won't accept directly\n",
        "for bad in ['verbosity', 'eval_metric']:\n",
        "    if bad in clf_params:\n",
        "        clf_params.pop(bad)\n",
        "\n",
        "print(\"\\nFinal params for XGBClassifier:\")\n",
        "print({k: clf_params[k] for k in ['n_estimators','max_depth','learning_rate'] if k in clf_params})\n",
        "\n",
        "clf = XGBClassifier(**clf_params)\n",
        "print(\"Training XGBoost on combined features... (may take a few minutes)\")\n",
        "clf.fit(X_train_s, y_train)\n",
        "\n",
        "# Evaluate on val and test\n",
        "def eval_and_print(model, Xv, yv, setname):\n",
        "    probs = model.predict_proba(Xv)[:,1]\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "    print(f\"\\n--- {setname} Evaluation ---\")\n",
        "    print(\"Accuracy: \", accuracy_score(yv, preds))\n",
        "    print(\"Precision:\", precision_score(yv, preds))\n",
        "    print(\"Recall:   \", recall_score(yv, preds))\n",
        "    print(\"F1 score: \", f1_score(yv, preds))\n",
        "    print(\"ROC AUC:  \", roc_auc_score(yv, probs))\n",
        "    print(\"Confusion matrix (tn, fp; fn, tp):\")\n",
        "    print(confusion_matrix(yv, preds))\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(yv, preds, digits=4))\n",
        "\n",
        "eval_and_print(clf, X_val_s, y_val, \"VALIDATION\")\n",
        "eval_and_print(clf, X_test_s, y_test, \"TEST (holdout)\")\n",
        "\n",
        "# Save final model and params\n",
        "model_path = os.path.join(OUT_MODEL_DIR, 'xgb_combined_final.joblib')\n",
        "joblib.dump(clf, model_path)\n",
        "with open(os.path.join(OUT_MODEL_DIR, 'xgb_combined_final_params.json'), 'w') as f:\n",
        "    json.dump(clf_params, f, indent=2)\n",
        "print(\"\\nSaved XGBoost model to:\", model_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
